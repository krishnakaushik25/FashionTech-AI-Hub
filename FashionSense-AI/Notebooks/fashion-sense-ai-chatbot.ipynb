{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":12110042,"sourceType":"datasetVersion","datasetId":7624511},{"sourceId":12085746,"sourceType":"datasetVersion","datasetId":7607963}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# *🛍️ Fashion Sense AI*","metadata":{}},{"cell_type":"markdown","source":"## 📂 Listing Files in a Directory using `os` Module\n\nThis code snippet demonstrates how to use Python’s built-in `os` module to interact with the file system. Specifically, it lists the contents of a given directory in the Kaggle notebook environment.","metadata":{}},{"cell_type":"code","source":"# Importing the os module which provides functions to interact with the operating system\nimport os\n\n# Using os.listdir to list all files and directories in the specified path\n# This will print the contents of the \"/kaggle/input/dataset-ecomerce/\" directory\nprint(os.listdir(\"/kaggle/input/dataset-ecomerce/\"))\nprint(os.listdir(\"/kaggle/input/hf-token\"))\n\n# I had taken 2 input source","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-22T16:17:31.197534Z","iopub.execute_input":"2025-06-22T16:17:31.198004Z","iopub.status.idle":"2025-06-22T16:17:31.215081Z","shell.execute_reply.started":"2025-06-22T16:17:31.197978Z","shell.execute_reply":"2025-06-22T16:17:31.214372Z"}},"outputs":[{"name":"stdout","text":"['dresses_bd_processed_data.csv', 'jeans_bd_processed_data.csv', 'Images']\n['hf_token.json']\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"## 📦 Installing Essential Libraries for ML, NLP, and App Development\n\nIn this step, we are preparing the Python environment by installing all the necessary libraries required for:\n\n### 🔢 Data Processing & Analysis\n- **`pandas`, `numpy`**: To handle structured data and perform numerical computations efficiently.\n\n### 📊 Data Visualization\n- **`matplotlib`, `seaborn`**: For creating insightful visualizations and exploratory data analysis.\n\n### 🤖 Machine Learning & Preprocessing\n- **`scikit-learn`**: For traditional ML models, feature scaling, model evaluation, and utilities.\n- **`tqdm`, `requests`**: To enhance user experience with progress bars and handle API requests.\n\n### 🧠 Transformers & Model Acceleration\n- **`transformers`, `accelerate`**: From Hugging Face, to load and run large language models efficiently.\n- **`bitsandbytes`, `flash-attn`**: To support low-bit quantization and fast attention for efficient model inference.\n\n### ✍️ Text Processing & Embeddings\n- **`ftfy`, `regex`**: To clean and normalize messy Unicode text.\n- **`sentence-transformers`**: For generating sentence embeddings used in similarity search or semantic understanding.\n\n### 🔍 Vector Search\n- **`faiss-gpu-cu12`**: Facebook’s library for efficient similarity search over vector embeddings using GPU (CUDA 12).\n\n### 🧠 LLM Integration & LangChain\n- **`langchain`, `langchain-community`, `openai`**: To build applications that integrate with language models like GPT using LangChain.\n\n### 🌐 App Interface\n- **`streamlit`**: To create and run a web-based interactive application with Python scripts.\n\n### 🔥 PyTorch Ecosystem\n- **`torch`, `torchvision`, `torchaudio`**: For deep learning, and to work with image and audio data in PyTorch-based projects.\n\n> ✅ These installations set up your environment for an end-to-end ML/NLP pipeline, including data handling, model deployment, LLM integration, and app development using Streamlit.\n","metadata":{}},{"cell_type":"code","source":"!pip install pandas numpy matplotlib seaborn scikit-learn requests tqdm transformers accelerate ftfy regex sentence-transformers faiss-gpu-cu12 langchain langchain-community streamlit # bitsandbytes # flash-attn\n!pip install torch torchvision torchaudio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T16:17:31.536527Z","iopub.execute_input":"2025-06-22T16:17:31.536779Z","iopub.status.idle":"2025-06-22T16:19:12.082586Z","shell.execute_reply.started":"2025-06-22T16:17:31.536761Z","shell.execute_reply":"2025-06-22T16:19:12.081822Z"},"scrolled":true},"outputs":[{"name":"stdout","text":"Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.3)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\nRequirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (3.7.2)\nRequirement already satisfied: seaborn in /usr/local/lib/python3.11/dist-packages (0.12.2)\nRequirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.2.2)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (2.32.3)\nRequirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (4.67.1)\nRequirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.51.3)\nRequirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.5.2)\nCollecting ftfy\n  Downloading ftfy-6.3.1-py3-none-any.whl.metadata (7.3 kB)\nRequirement already satisfied: regex in /usr/local/lib/python3.11/dist-packages (2024.11.6)\nRequirement already satisfied: sentence-transformers in /usr/local/lib/python3.11/dist-packages (3.4.1)\nCollecting faiss-gpu-cu12\n  Downloading faiss_gpu_cu12-1.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\nRequirement already satisfied: langchain in /usr/local/lib/python3.11/dist-packages (0.3.22)\nCollecting langchain-community\n  Downloading langchain_community-0.3.26-py3-none-any.whl.metadata (2.9 kB)\nCollecting streamlit\n  Downloading streamlit-1.46.0-py3-none-any.whl.metadata (9.0 kB)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy) (2.4.1)\nRequirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.3.1)\nRequirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (0.12.1)\nRequirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (4.57.0)\nRequirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (1.4.8)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (25.0)\nRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (11.1.0)\nRequirement already satisfied: pyparsing<3.1,>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib) (3.0.9)\nRequirement already satisfied: scipy>=1.3.2 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.15.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.6.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests) (2025.4.26)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.18.0)\nRequirement already satisfied: huggingface-hub<1.0,>=0.30.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.31.1)\nRequirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\nRequirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.1)\nRequirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.3)\nRequirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (7.0.0)\nRequirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.6.0+cu124)\nRequirement already satisfied: wcwidth in /usr/local/lib/python3.11/dist-packages (from ftfy) (0.2.13)\nRequirement already satisfied: nvidia-cuda-runtime-cu12>=12.1.105 in /usr/local/lib/python3.11/dist-packages (from faiss-gpu-cu12) (12.4.127)\nRequirement already satisfied: nvidia-cublas-cu12>=12.1.3.1 in /usr/local/lib/python3.11/dist-packages (from faiss-gpu-cu12) (12.9.0.13)\nRequirement already satisfied: langchain-core<1.0.0,>=0.3.49 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.50)\nRequirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.7)\nRequirement already satisfied: langsmith<0.4,>=0.1.17 in /usr/local/lib/python3.11/dist-packages (from langchain) (0.3.23)\nRequirement already satisfied: pydantic<3.0.0,>=2.7.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.11.4)\nRequirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.11/dist-packages (from langchain) (2.0.40)\nCollecting langchain-core<1.0.0,>=0.3.49 (from langchain)\n  Downloading langchain_core-0.3.66-py3-none-any.whl.metadata (5.8 kB)\nCollecting langchain\n  Downloading langchain-0.3.26-py3-none-any.whl.metadata (7.8 kB)\nRequirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (3.11.18)\nRequirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (9.1.2)\nRequirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.11/dist-packages (from langchain-community) (0.6.7)\nCollecting pydantic-settings<3.0.0,>=2.4.0 (from langchain-community)\n  Downloading pydantic_settings-2.10.0-py3-none-any.whl.metadata (3.4 kB)\nCollecting httpx-sse<1.0.0,>=0.4.0 (from langchain-community)\n  Downloading httpx_sse-0.4.0-py3-none-any.whl.metadata (9.0 kB)\nCollecting langchain-text-splitters<1.0.0,>=0.3.8 (from langchain)\n  Downloading langchain_text_splitters-0.3.8-py3-none-any.whl.metadata (1.9 kB)\nRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.0)\nRequirement already satisfied: blinker<2,>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (1.9.0)\nRequirement already satisfied: cachetools<7,>=4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (5.5.2)\nRequirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (8.1.8)\nRequirement already satisfied: protobuf<7,>=3.20 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.20.3)\nRequirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (19.0.1)\nRequirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.11/dist-packages (from streamlit) (0.10.2)\nRequirement already satisfied: typing-extensions<5,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from streamlit) (4.13.2)\nRequirement already satisfied: watchdog<7,>=2.1.5 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.0.0)\nRequirement already satisfied: gitpython!=3.1.19,<4,>=3.0.7 in /usr/local/lib/python3.11/dist-packages (from streamlit) (3.1.44)\nCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n  Downloading pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\nRequirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in /usr/local/lib/python3.11/dist-packages (from streamlit) (6.4.2)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain-community) (1.20.0)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (3.1.6)\nRequirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (4.23.0)\nRequirement already satisfied: narwhals>=1.14.2 in /usr/local/lib/python3.11/dist-packages (from altair<6,>=4.0->streamlit) (1.33.0)\nRequirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (3.26.1)\nRequirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain-community) (0.9.0)\nRequirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.19,<4,>=3.0.7->streamlit) (4.0.12)\nRequirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (2025.3.2)\nRequirement already satisfied: hf-xet<2.0.0,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.30.0->transformers) (1.1.0)\nCollecting langsmith>=0.1.125 (from langchain-community)\n  Downloading langsmith-0.4.1-py3-none-any.whl.metadata (15 kB)\nRequirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.11/dist-packages (from langchain-core<1.0.0,>=0.3.49->langchain) (1.33)\nCollecting packaging>=20.0 (from matplotlib)\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.28.1)\nRequirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (3.10.16)\nRequirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (1.0.0)\nRequirement already satisfied: zstandard<0.24.0,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from langsmith>=0.1.125->langchain-community) (0.23.0)\nRequirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.7.0)\nRequirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (2.33.2)\nRequirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3.0.0,>=2.7.4->langchain) (0.4.0)\nCollecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.4.0->langchain-community)\n  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.1.1)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cublas-cu12>=12.1.3.1 (from faiss-gpu-cu12)\n  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-curand-cu12==10.3.5.147 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nCollecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nCollecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\nCollecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2.0.0->accelerate)\n  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy) (2024.2.0)\nRequirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit) (5.0.2)\nRequirement already satisfied: anyio in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (4.9.0)\nRequirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.0.7)\nRequirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (0.14.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy) (2024.2.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (3.0.2)\nRequirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.11/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.49->langchain) (3.0.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.24.0)\nRequirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain-community) (1.1.0)\nRequirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.11/dist-packages (from anyio->httpx<1,>=0.23.0->langsmith>=0.1.125->langchain-community) (1.3.1)\nDownloading ftfy-6.3.1-py3-none-any.whl (44 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.8/44.8 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading faiss_gpu_cu12-1.11.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (48.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.0/48.0 MB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading langchain_community-0.3.26-py3-none-any.whl (2.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m65.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25hDownloading langchain-0.3.26-py3-none-any.whl (1.0 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m40.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading streamlit-1.46.0-py3-none-any.whl (10.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.1/10.1 MB\u001b[0m \u001b[31m104.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[?25hDownloading httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\nDownloading langchain_core-0.3.66-py3-none-any.whl (438 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.9/438.9 kB\u001b[0m \u001b[31m26.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading langchain_text_splitters-0.3.8-py3-none-any.whl (32 kB)\nDownloading langsmith-0.4.1-py3-none-any.whl (364 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m364.6/364.6 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydantic_settings-2.10.0-py3-none-any.whl (45 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.2/45.2 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m93.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m24.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m13.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m86.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\nInstalling collected packages: python-dotenv, packaging, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cublas-cu12, httpx-sse, ftfy, nvidia-cusparse-cu12, nvidia-cudnn-cu12, pydantic-settings, nvidia-cusolver-cu12, langsmith, langchain-core, langchain-text-splitters, langchain, pydeck, streamlit, langchain-community, faiss-gpu-cu12\n  Attempting uninstall: packaging\n    Found existing installation: packaging 25.0\n    Uninstalling packaging-25.0:\n      Successfully uninstalled packaging-25.0\n  Attempting uninstall: nvidia-nvjitlink-cu12\n    Found existing installation: nvidia-nvjitlink-cu12 12.9.41\n    Uninstalling nvidia-nvjitlink-cu12-12.9.41:\n      Successfully uninstalled nvidia-nvjitlink-cu12-12.9.41\n  Attempting uninstall: nvidia-curand-cu12\n    Found existing installation: nvidia-curand-cu12 10.3.10.19\n    Uninstalling nvidia-curand-cu12-10.3.10.19:\n      Successfully uninstalled nvidia-curand-cu12-10.3.10.19\n  Attempting uninstall: nvidia-cufft-cu12\n    Found existing installation: nvidia-cufft-cu12 11.4.0.6\n    Uninstalling nvidia-cufft-cu12-11.4.0.6:\n      Successfully uninstalled nvidia-cufft-cu12-11.4.0.6\n  Attempting uninstall: nvidia-cublas-cu12\n    Found existing installation: nvidia-cublas-cu12 12.9.0.13\n    Uninstalling nvidia-cublas-cu12-12.9.0.13:\n      Successfully uninstalled nvidia-cublas-cu12-12.9.0.13\n  Attempting uninstall: nvidia-cusparse-cu12\n    Found existing installation: nvidia-cusparse-cu12 12.5.9.5\n    Uninstalling nvidia-cusparse-cu12-12.5.9.5:\n      Successfully uninstalled nvidia-cusparse-cu12-12.5.9.5\n  Attempting uninstall: nvidia-cudnn-cu12\n    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n  Attempting uninstall: nvidia-cusolver-cu12\n    Found existing installation: nvidia-cusolver-cu12 11.7.4.40\n    Uninstalling nvidia-cusolver-cu12-11.7.4.40:\n      Successfully uninstalled nvidia-cusolver-cu12-11.7.4.40\n  Attempting uninstall: langsmith\n    Found existing installation: langsmith 0.3.23\n    Uninstalling langsmith-0.3.23:\n      Successfully uninstalled langsmith-0.3.23\n  Attempting uninstall: langchain-core\n    Found existing installation: langchain-core 0.3.50\n    Uninstalling langchain-core-0.3.50:\n      Successfully uninstalled langchain-core-0.3.50\n  Attempting uninstall: langchain-text-splitters\n    Found existing installation: langchain-text-splitters 0.3.7\n    Uninstalling langchain-text-splitters-0.3.7:\n      Successfully uninstalled langchain-text-splitters-0.3.7\n  Attempting uninstall: langchain\n    Found existing installation: langchain 0.3.22\n    Uninstalling langchain-0.3.22:\n      Successfully uninstalled langchain-0.3.22\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed faiss-gpu-cu12-1.11.0 ftfy-6.3.1 httpx-sse-0.4.0 langchain-0.3.26 langchain-community-0.3.26 langchain-core-0.3.66 langchain-text-splitters-0.3.8 langsmith-0.4.1 nvidia-cublas-cu12-12.4.5.8 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 packaging-24.2 pydantic-settings-2.10.0 pydeck-0.9.1 python-dotenv-1.1.0 streamlit-1.46.0\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\nRequirement already satisfied: torchaudio in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchvision) (1.26.4)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.1.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy->torchvision) (2.4.1)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy->torchvision) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy->torchvision) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy->torchvision) (2024.2.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy->torchvision) (2024.2.0)\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"## 📄 Loading Fashion Product Data with pandas\n\nIn this step, we are importing structured product data related to dresses and jeans from CSV files. These datasets are stored in the Kaggle environment and will be used for downstream tasks like visual search, recommendation, or metadata-based filtering.\n\n### 🔍 Breakdown:\n\n- **`import pandas as pd`**: Imports the `pandas` library, which is essential for working with tabular data (e.g., CSV files).\n- **`import numpy as np`**: Imports NumPy for numerical operations, often used later for feature engineering or matrix computations.\n\n### 📥 Reading Product Datasets:\n\n- **`dress = pd.read_csv(...)`**: Loads the **dresses** dataset into a DataFrame. This file likely contains features such as product IDs, categories, colors, brands, prices, and possibly image paths or descriptions.\n- **`jeans = pd.read_csv(...)`**: Loads the **jeans** dataset in a similar fashion.\n\n### 👁️ Displaying the Data:\n\n- **`display(dress)` and `display(jeans)`**: Used to visualize the top rows of each dataset within a Jupyter or Kaggle notebook environment. This helps confirm that the data has been loaded correctly and gives a quick overview of available columns and values.\n\n> ✅ These datasets form the foundation for performing visual similarity search, outfit recommendation, and trend analysis in the fashion domain.","metadata":{}},{"cell_type":"code","source":"# Importing the pandas library as 'pd' for data manipulation and analysis\nimport pandas as pd\n\n# Importing the numpy library as 'np' for numerical operations\nimport numpy as np\n\n# Reading the processed dress dataset CSV file into a pandas DataFrame named 'dress'\ndress = pd.read_csv(r'/kaggle/input/dataset-ecomerce/dresses_bd_processed_data.csv')\n\n# Reading the processed jeans dataset CSV file into a pandas DataFrame named 'jeans'\njeans = pd.read_csv(r'/kaggle/input/dataset-ecomerce/jeans_bd_processed_data.csv')\n\n# Displaying the contents of the 'dress' DataFrame in a readable table format (Kaggle/Notebook compatible)\ndisplay(dress)\n\n# Displaying the contents of the 'jeans' DataFrame similarly\ndisplay(jeans)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T16:19:12.084172Z","iopub.execute_input":"2025-06-22T16:19:12.084432Z","iopub.status.idle":"2025-06-22T16:19:13.268516Z","shell.execute_reply.started":"2025-06-22T16:19:12.084408Z","shell.execute_reply":"2025-06-22T16:19:13.267864Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"              selling_price  discount  category_id  \\\n0      {'INR': 474848.9539}       0.0           30   \n1      {'INR': 464648.6919}       0.0           30   \n2       {'INR': 29496.0812}       0.0           30   \n3       {'INR': 17156.9392}       0.0           30   \n4       {'INR': 26079.5467}       0.0           30   \n...                     ...       ...          ...   \n14604   {'INR': 34051.4605}       0.0           30   \n14605   {'INR': 20385.3225}       0.0           30   \n14606   {'INR': 15829.9432}       0.0           30   \n14607   {'INR': 20141.6973}       0.0           30   \n14608   {'INR': 18107.6328}       0.0           30   \n\n                                               meta_info  \\\n0      Slim fit. Designed to hit at the ankle. UK siz...   \n1      Slim fit. Designed to hit at the ankle. UK siz...   \n2      Fit-and-flare silhouette. Intended to hit at t...   \n3      Fits true to size; take your normal size, Stra...   \n4      Fit-and-flare silhouette Designed to hit at th...   \n...                                                  ...   \n14604  Main 74% TENCEL™ lyocell, 26% Nylon. Lining 10...   \n14605  100% Recycled polyester. Composition Machine w...   \n14606  73% LENZING™ ECOVERO™ Viscose, 27% Nylon. Comp...   \n14607  63% Organic cotton, 37% TENCEL™ lyocell. Compo...   \n14608  100% Other fibres. Composition Machine washabl...   \n\n                                              product_id  \\\n0      b613d7b5dfe86f3e695d931d31fd729fdf44e181f14079...   \n1      482b10a23f8d00cfc7c9bbeeac4e26d25dd303d8e62e97...   \n2      3508b052ef7a5eea820423b97713612bc92a3f2301a3d3...   \n3      6360245240b68885bd4dbcef8d8856c0fb13f1314769f5...   \n4      5d07037957e64d1e218499cb7d7a8e5e57aa59249bb806...   \n...                                                  ...   \n14604  d71430db83e8a11f846346898ea7f8dd96417a8c0e329e...   \n14605  007f57fb3e8400242e620ce37becada006306e68df606e...   \n14606  70f3e724958742d76ca2dff07b563bdfc43eca78d88b5c...   \n14607  b5598a5048205634fc7465aae62dc24fefd9fc61ab1b1d...   \n14608  62aff546c9fc48f04c14c81e7f90ac4b660dbc1722d13e...   \n\n                                                 pdp_url           sku  \\\n0      https://www.ralphlauren.co.uk/en/kristian-silk...        479495   \n1      https://www.ralphlauren.co.uk/en/kristian-silk...        502670   \n2      https://www.ralphlauren.co.uk/en/fit-and-flare...        478766   \n3      https://www.anthropologie.com/shop/adena-crepe...  50297209_041   \n4      https://www.ralphlauren.co.uk/en/belted-cotton...        478750   \n...                                                  ...           ...   \n14604  https://www.next.co.uk/style/su724260/h28422#h...        H28422   \n14605  https://www.next.co.uk/style/su700558/h14377#h...        H14377   \n14606  https://www.next.co.uk/style/su747355/h45925#h...        H45925   \n14607  https://www.next.co.uk/style/su747618/w52702#w...        W52702   \n14608  https://www.next.co.uk/style/su710223/h20172#h...        H20172   \n\n              brand  department_id last_seen_date   launch_on  \\\n0      RALPH LAUREN              2     2025-05-01  2020-02-29   \n1      RALPH LAUREN              2     2025-05-08  2020-02-29   \n2      RALPH LAUREN              2     2025-05-08  2020-02-29   \n3             BHLDN              2     2025-01-31  2020-05-27   \n4      RALPH LAUREN              2     2025-05-08  2021-02-12   \n...             ...            ...            ...         ...   \n14604    All Saints              2     2025-05-08  2025-04-29   \n14605    All Saints              2     2025-05-08  2025-05-01   \n14606    All Saints              2     2025-05-08  2025-05-01   \n14607    All Saints              2     2025-05-01  2025-05-01   \n14608    All Saints              2     2025-05-08  2025-05-01   \n\n                        mrp                        product_name  \\\n0      {'INR': 474848.9539}          Kristian Silk Tuxedo Dress   \n1      {'INR': 464648.6919}          Kristian Silk Tuxedo Dress   \n2       {'INR': 29496.0812}            Fit-and-Flare Shirtdress   \n3       {'INR': 17156.9392}                   Adena Crepe Dress   \n4       {'INR': 26079.5467}      Belted Cotton-Blend Shirtdress   \n...                     ...                                 ...   \n14604   {'INR': 34051.4605}        AllSaints Cream Sienna Dress   \n14605   {'INR': 20385.3225}         AllSaints White Rosie Dress   \n14606   {'INR': 15829.9432}         AllSaints Brown Arwen Dress   \n14607   {'INR': 20141.6973}  AllSaints Brown Faye Shacket Dress   \n14608   {'INR': 18107.6328}    AllSaints Black Kathy Mesh Dress   \n\n                                        feature_image_s3  channel_id  \\\n0      https://gallery.stylumia.com/originals/2020/02...          14   \n1      https://gallery.stylumia.com/originals/2020/02...          14   \n2      https://gallery.stylumia.com/originals/2020/02...          14   \n3      https://gallery.stylumia.com/originals/2020/05...          48   \n4      https://gallery.stylumia.com/originals/2021/02...          14   \n...                                                  ...         ...   \n14604  https://gallery.stylumia.com/originals/2025/04...         240   \n14605  https://gallery.stylumia.com/originals/2025/05...         240   \n14606  https://gallery.stylumia.com/originals/2025/05...         240   \n14607  https://gallery.stylumia.com/originals/2025/05...         240   \n14608  https://gallery.stylumia.com/originals/2025/05...         240   \n\n                                            feature_list  \\\n0      ['Slim fit. Designed to hit at the ankle.', 'U...   \n1      ['Slim fit. Designed to hit at the ankle.', 'U...   \n2      ['Fit-and-flare silhouette. Intended to hit at...   \n3      ['Back zip', 'Polyester; polyester lining', 'P...   \n4      ['Fit-and-flare silhouette Designed to hit at ...   \n...                                                  ...   \n14604                                                 []   \n14605  ['Regular', 'Cowl neck', 'Short sleeve', 'Midi...   \n14606        ['Round neck', 'Sleeveless', 'Maxi length']   \n14607                                                 []   \n14608                                                 []   \n\n                                             description  \\\n0      The Kristian evening dress is informed by the ...   \n1      The Kristian evening dress is informed by the ...   \n2      Airy georgette and a flattering fit-and-flare ...   \n3      A sleek square neckline tops this stretchy, bo...   \n4      This iteration of Lauren's iconic shirtdress i...   \n...                                                  ...   \n14604    Slim fit. V-Neck. Shoulder straps. Maxi length.   \n14605                                                NaN   \n14606                                                NaN   \n14607                 Collar. Long sleeve. Short length.   \n14608                                                NaN   \n\n                                        style_attributes  \\\n0                                                     {}   \n1                                                     {}   \n2                                                     {}   \n3      {'modelNotes': '', 'dimensions': 'Fits true to...   \n4                                                     {}   \n...                                                  ...   \n14604  {'Composition': 'Main 74% TENCEL™ lyocell, 26%...   \n14605  {'Composition': '100% Recycled polyester.', 'W...   \n14606  {'Composition': '73% LENZING™ ECOVERO™ Viscose...   \n14607  {'Composition': '63% Organic cotton, 37% TENCE...   \n14608  {'Composition': '100% Other fibres.', 'Washing...   \n\n                                           pdp_images_s3  \n0      ['https://gallery.stylumia.com/originals/2020/...  \n1      ['https://gallery.stylumia.com/originals/2020/...  \n2      ['https://gallery.stylumia.com/originals/2020/...  \n3      ['https://gallery.stylumia.com/originals/2020/...  \n4      ['https://gallery.stylumia.com/originals/2021/...  \n...                                                  ...  \n14604  ['https://gallery.stylumia.com/originals/2025/...  \n14605  ['https://gallery.stylumia.com/originals/2025/...  \n14606  ['https://gallery.stylumia.com/originals/2025/...  \n14607  ['https://gallery.stylumia.com/originals/2025/...  \n14608  ['https://gallery.stylumia.com/originals/2025/...  \n\n[14609 rows x 19 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>selling_price</th>\n      <th>discount</th>\n      <th>category_id</th>\n      <th>meta_info</th>\n      <th>product_id</th>\n      <th>pdp_url</th>\n      <th>sku</th>\n      <th>brand</th>\n      <th>department_id</th>\n      <th>last_seen_date</th>\n      <th>launch_on</th>\n      <th>mrp</th>\n      <th>product_name</th>\n      <th>feature_image_s3</th>\n      <th>channel_id</th>\n      <th>feature_list</th>\n      <th>description</th>\n      <th>style_attributes</th>\n      <th>pdp_images_s3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>{'INR': 474848.9539}</td>\n      <td>0.0</td>\n      <td>30</td>\n      <td>Slim fit. Designed to hit at the ankle. UK siz...</td>\n      <td>b613d7b5dfe86f3e695d931d31fd729fdf44e181f14079...</td>\n      <td>https://www.ralphlauren.co.uk/en/kristian-silk...</td>\n      <td>479495</td>\n      <td>RALPH LAUREN</td>\n      <td>2</td>\n      <td>2025-05-01</td>\n      <td>2020-02-29</td>\n      <td>{'INR': 474848.9539}</td>\n      <td>Kristian Silk Tuxedo Dress</td>\n      <td>https://gallery.stylumia.com/originals/2020/02...</td>\n      <td>14</td>\n      <td>['Slim fit. Designed to hit at the ankle.', 'U...</td>\n      <td>The Kristian evening dress is informed by the ...</td>\n      <td>{}</td>\n      <td>['https://gallery.stylumia.com/originals/2020/...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{'INR': 464648.6919}</td>\n      <td>0.0</td>\n      <td>30</td>\n      <td>Slim fit. Designed to hit at the ankle. UK siz...</td>\n      <td>482b10a23f8d00cfc7c9bbeeac4e26d25dd303d8e62e97...</td>\n      <td>https://www.ralphlauren.co.uk/en/kristian-silk...</td>\n      <td>502670</td>\n      <td>RALPH LAUREN</td>\n      <td>2</td>\n      <td>2025-05-08</td>\n      <td>2020-02-29</td>\n      <td>{'INR': 464648.6919}</td>\n      <td>Kristian Silk Tuxedo Dress</td>\n      <td>https://gallery.stylumia.com/originals/2020/02...</td>\n      <td>14</td>\n      <td>['Slim fit. Designed to hit at the ankle.', 'U...</td>\n      <td>The Kristian evening dress is informed by the ...</td>\n      <td>{}</td>\n      <td>['https://gallery.stylumia.com/originals/2020/...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{'INR': 29496.0812}</td>\n      <td>0.0</td>\n      <td>30</td>\n      <td>Fit-and-flare silhouette. Intended to hit at t...</td>\n      <td>3508b052ef7a5eea820423b97713612bc92a3f2301a3d3...</td>\n      <td>https://www.ralphlauren.co.uk/en/fit-and-flare...</td>\n      <td>478766</td>\n      <td>RALPH LAUREN</td>\n      <td>2</td>\n      <td>2025-05-08</td>\n      <td>2020-02-29</td>\n      <td>{'INR': 29496.0812}</td>\n      <td>Fit-and-Flare Shirtdress</td>\n      <td>https://gallery.stylumia.com/originals/2020/02...</td>\n      <td>14</td>\n      <td>['Fit-and-flare silhouette. Intended to hit at...</td>\n      <td>Airy georgette and a flattering fit-and-flare ...</td>\n      <td>{}</td>\n      <td>['https://gallery.stylumia.com/originals/2020/...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{'INR': 17156.9392}</td>\n      <td>0.0</td>\n      <td>30</td>\n      <td>Fits true to size; take your normal size, Stra...</td>\n      <td>6360245240b68885bd4dbcef8d8856c0fb13f1314769f5...</td>\n      <td>https://www.anthropologie.com/shop/adena-crepe...</td>\n      <td>50297209_041</td>\n      <td>BHLDN</td>\n      <td>2</td>\n      <td>2025-01-31</td>\n      <td>2020-05-27</td>\n      <td>{'INR': 17156.9392}</td>\n      <td>Adena Crepe Dress</td>\n      <td>https://gallery.stylumia.com/originals/2020/05...</td>\n      <td>48</td>\n      <td>['Back zip', 'Polyester; polyester lining', 'P...</td>\n      <td>A sleek square neckline tops this stretchy, bo...</td>\n      <td>{'modelNotes': '', 'dimensions': 'Fits true to...</td>\n      <td>['https://gallery.stylumia.com/originals/2020/...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{'INR': 26079.5467}</td>\n      <td>0.0</td>\n      <td>30</td>\n      <td>Fit-and-flare silhouette Designed to hit at th...</td>\n      <td>5d07037957e64d1e218499cb7d7a8e5e57aa59249bb806...</td>\n      <td>https://www.ralphlauren.co.uk/en/belted-cotton...</td>\n      <td>478750</td>\n      <td>RALPH LAUREN</td>\n      <td>2</td>\n      <td>2025-05-08</td>\n      <td>2021-02-12</td>\n      <td>{'INR': 26079.5467}</td>\n      <td>Belted Cotton-Blend Shirtdress</td>\n      <td>https://gallery.stylumia.com/originals/2021/02...</td>\n      <td>14</td>\n      <td>['Fit-and-flare silhouette Designed to hit at ...</td>\n      <td>This iteration of Lauren's iconic shirtdress i...</td>\n      <td>{}</td>\n      <td>['https://gallery.stylumia.com/originals/2021/...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>14604</th>\n      <td>{'INR': 34051.4605}</td>\n      <td>0.0</td>\n      <td>30</td>\n      <td>Main 74% TENCEL™ lyocell, 26% Nylon. Lining 10...</td>\n      <td>d71430db83e8a11f846346898ea7f8dd96417a8c0e329e...</td>\n      <td>https://www.next.co.uk/style/su724260/h28422#h...</td>\n      <td>H28422</td>\n      <td>All Saints</td>\n      <td>2</td>\n      <td>2025-05-08</td>\n      <td>2025-04-29</td>\n      <td>{'INR': 34051.4605}</td>\n      <td>AllSaints Cream Sienna Dress</td>\n      <td>https://gallery.stylumia.com/originals/2025/04...</td>\n      <td>240</td>\n      <td>[]</td>\n      <td>Slim fit. V-Neck. Shoulder straps. Maxi length.</td>\n      <td>{'Composition': 'Main 74% TENCEL™ lyocell, 26%...</td>\n      <td>['https://gallery.stylumia.com/originals/2025/...</td>\n    </tr>\n    <tr>\n      <th>14605</th>\n      <td>{'INR': 20385.3225}</td>\n      <td>0.0</td>\n      <td>30</td>\n      <td>100% Recycled polyester. Composition Machine w...</td>\n      <td>007f57fb3e8400242e620ce37becada006306e68df606e...</td>\n      <td>https://www.next.co.uk/style/su700558/h14377#h...</td>\n      <td>H14377</td>\n      <td>All Saints</td>\n      <td>2</td>\n      <td>2025-05-08</td>\n      <td>2025-05-01</td>\n      <td>{'INR': 20385.3225}</td>\n      <td>AllSaints White Rosie Dress</td>\n      <td>https://gallery.stylumia.com/originals/2025/05...</td>\n      <td>240</td>\n      <td>['Regular', 'Cowl neck', 'Short sleeve', 'Midi...</td>\n      <td>NaN</td>\n      <td>{'Composition': '100% Recycled polyester.', 'W...</td>\n      <td>['https://gallery.stylumia.com/originals/2025/...</td>\n    </tr>\n    <tr>\n      <th>14606</th>\n      <td>{'INR': 15829.9432}</td>\n      <td>0.0</td>\n      <td>30</td>\n      <td>73% LENZING™ ECOVERO™ Viscose, 27% Nylon. Comp...</td>\n      <td>70f3e724958742d76ca2dff07b563bdfc43eca78d88b5c...</td>\n      <td>https://www.next.co.uk/style/su747355/h45925#h...</td>\n      <td>H45925</td>\n      <td>All Saints</td>\n      <td>2</td>\n      <td>2025-05-08</td>\n      <td>2025-05-01</td>\n      <td>{'INR': 15829.9432}</td>\n      <td>AllSaints Brown Arwen Dress</td>\n      <td>https://gallery.stylumia.com/originals/2025/05...</td>\n      <td>240</td>\n      <td>['Round neck', 'Sleeveless', 'Maxi length']</td>\n      <td>NaN</td>\n      <td>{'Composition': '73% LENZING™ ECOVERO™ Viscose...</td>\n      <td>['https://gallery.stylumia.com/originals/2025/...</td>\n    </tr>\n    <tr>\n      <th>14607</th>\n      <td>{'INR': 20141.6973}</td>\n      <td>0.0</td>\n      <td>30</td>\n      <td>63% Organic cotton, 37% TENCEL™ lyocell. Compo...</td>\n      <td>b5598a5048205634fc7465aae62dc24fefd9fc61ab1b1d...</td>\n      <td>https://www.next.co.uk/style/su747618/w52702#w...</td>\n      <td>W52702</td>\n      <td>All Saints</td>\n      <td>2</td>\n      <td>2025-05-01</td>\n      <td>2025-05-01</td>\n      <td>{'INR': 20141.6973}</td>\n      <td>AllSaints Brown Faye Shacket Dress</td>\n      <td>https://gallery.stylumia.com/originals/2025/05...</td>\n      <td>240</td>\n      <td>[]</td>\n      <td>Collar. Long sleeve. Short length.</td>\n      <td>{'Composition': '63% Organic cotton, 37% TENCE...</td>\n      <td>['https://gallery.stylumia.com/originals/2025/...</td>\n    </tr>\n    <tr>\n      <th>14608</th>\n      <td>{'INR': 18107.6328}</td>\n      <td>0.0</td>\n      <td>30</td>\n      <td>100% Other fibres. Composition Machine washabl...</td>\n      <td>62aff546c9fc48f04c14c81e7f90ac4b660dbc1722d13e...</td>\n      <td>https://www.next.co.uk/style/su710223/h20172#h...</td>\n      <td>H20172</td>\n      <td>All Saints</td>\n      <td>2</td>\n      <td>2025-05-08</td>\n      <td>2025-05-01</td>\n      <td>{'INR': 18107.6328}</td>\n      <td>AllSaints Black Kathy Mesh Dress</td>\n      <td>https://gallery.stylumia.com/originals/2025/05...</td>\n      <td>240</td>\n      <td>[]</td>\n      <td>NaN</td>\n      <td>{'Composition': '100% Other fibres.', 'Washing...</td>\n      <td>['https://gallery.stylumia.com/originals/2025/...</td>\n    </tr>\n  </tbody>\n</table>\n<p>14609 rows × 19 columns</p>\n</div>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"          selling_price   discount  category_id  \\\n0     {'USD': 285.9978}   0.000000           56   \n1     {'USD': 285.9978}   0.000000           56   \n2     {'USD': 392.4156}   0.000000           56   \n3     {'USD': 170.4379}  40.174672           56   \n4     {'USD': 184.6675}   0.000000           56   \n...                 ...        ...          ...   \n2869     {'USD': 420.0}   0.000000           56   \n2870   {'USD': 92.8447}   0.000000           56   \n2871   {'USD': 79.7574}   0.000000           56   \n2872  {'USD': 185.9961}   0.000000           56   \n2873  {'USD': 291.3187}   0.000000           56   \n\n                                              meta_info  \\\n0     Skinny Fit: Mid-rise. Sits at the hip. Skinny ...   \n1     Skinny Fit: mid-rise. Sits at the hip. Skinny ...   \n2     Boy Fit: mid-rise. Sits at the hip. Relaxed th...   \n3     The Jenn Flare: Our flare sits at your true wa...   \n4     High-Rise Skinny Ankle: sits above the natural...   \n...                                                 ...   \n2869  Main material: 100% cotton, Secondary material...   \n2870  Exterior: 100% cotton Composition MACHINE WASH...   \n2871  Exterior: 50% cotton, Exterior: 50% lyocell Co...   \n2872  Petite Fit 100% Cotton., Machine washable. Car...   \n2873  Curved Tapered: Our curved tapered jean has a ...   \n\n                                             product_id  \\\n0     f4d992cf595405c44737ad1ff406360c9e7af5dc521020...   \n1     4c50e2a967da813d5b55452883e47ea7635e6f1972f1c9...   \n2     2e37dd2d1b28c4df27175c39bb01f13320be5267cd7e24...   \n3     264387126c9841fe4bd9607926c3e6155bbefd53badbfc...   \n4     06ebbee1d18f36444c87fd746cd7ce5ff24b943a89f0f6...   \n...                                                 ...   \n2869  f9fbee3a68a110f65c2dcaa01d00ed3fc787d3b367c519...   \n2870  a99c8e83ff86ce01228b54b0c8640d99adfca0a7755550...   \n2871  fcf79b834d61cd5ce9430a807ef218a2b9a8b5a906f309...   \n2872  05bb642a205ba1a24261cc662557cc9cdd1fc732d2664d...   \n2873  36d4b1e2e52ed98d4907c77f452416f3e15fac36c8de87...   \n\n                                                pdp_url  \\\n0     https://www.ralphlauren.co.uk/en/skinny-stretc...   \n1     https://www.ralphlauren.co.uk/en/stretch-skinn...   \n2     https://www.ralphlauren.co.uk/en/boy-fit-strai...   \n3     https://www.ralphlauren.co.uk/en/jenn-flare-je...   \n4     https://www.ralphlauren.co.uk/en/high-rise-ski...   \n...                                                 ...   \n2869  https://us.sandro-paris.com/en/p/wide-leg-stri...   \n2870  https://www.massimodutti.com/gb/midrise-straig...   \n2871  https://www.massimodutti.com/gb/highwaist-wide...   \n2872  https://www.reiss.com/style/su699374/h14421#h1...   \n2873  https://www.ralphlauren.co.uk/en/curved-tapere...   \n\n                                   sku          brand  department_id  \\\n0                               398475   RALPH LAUREN              2   \n1                               398474   RALPH LAUREN              2   \n2                               537869   RALPH LAUREN              2   \n3                               563799   RALPH LAUREN              2   \n4                               561065   RALPH LAUREN              2   \n...                                ...            ...            ...   \n2869  d15edac77f1eadddd847303ce2ce10cf   Sandro Paris              2   \n2870                      48640767/407  Massimo Dutti              2   \n2871                      49228723/800  Massimo Dutti              2   \n2872                            H14421        Belinda              2   \n2873                         100043242   RALPH LAUREN              2   \n\n     last_seen_date   launch_on                mrp  \\\n0        2025-05-15  2020-02-29  {'USD': 285.9978}   \n1        2025-05-15  2020-02-29  {'USD': 285.9978}   \n2        2025-05-15  2020-08-13  {'USD': 392.4156}   \n3        2025-01-28  2021-01-17  {'USD': 284.8925}   \n4        2025-05-01  2021-02-16  {'USD': 184.6675}   \n...             ...         ...                ...   \n2869     2025-05-09  2025-04-30     {'USD': 420.0}   \n2870     2025-05-02  2025-04-30   {'USD': 92.8447}   \n2871     2025-05-09  2025-04-30   {'USD': 79.7574}   \n2872     2025-05-01  2025-05-01  {'USD': 185.9961}   \n2873     2025-05-15  2025-05-01  {'USD': 291.3187}   \n\n                                       product_name  \\\n0                              Skinny Stretch Jeans   \n1                              Stretch Skinny Jeans   \n2                            Boy Fit Straight Jeans   \n3                                   Jenn Flare Jean   \n4                       High-Rise Skinny Ankle Jean   \n...                                             ...   \n2869                         Wide-leg striped jeans   \n2870                    Mid-rise straight-leg jeans   \n2871    High-waist wide-leg jeans with seam details   \n2872  Petite Straight-Leg Turn-Up Jeans in Mid Blue   \n2873                            Curved Tapered Jean   \n\n                                       feature_image_s3  channel_id  \\\n0     https://gallery.stylumia.com/originals/2020/02...          14   \n1     https://gallery.stylumia.com/originals/2020/02...          14   \n2     https://gallery.stylumia.com/originals/2020/08...          14   \n3     https://gallery.stylumia.com/originals/2021/01...          14   \n4     https://gallery.stylumia.com/originals/2021/02...          14   \n...                                                 ...         ...   \n2869  https://gallery.stylumia.com/originals/2025/04...         383   \n2870  https://gallery.stylumia.com/originals/2025/04...           7   \n2871  https://gallery.stylumia.com/originals/2025/04...           7   \n2872  https://gallery.stylumia.com/originals/2025/05...         299   \n2873  https://gallery.stylumia.com/originals/2025/05...          14   \n\n                                           feature_list  \\\n0     ['Skinny Fit: Mid-rise. Sits at the hip. Skinn...   \n1     ['Skinny Fit: mid-rise. Sits at the hip. Skinn...   \n2     ['Boy Fit: mid-rise. Sits at the hip. Relaxed ...   \n3     ['The Jenn Flare: Our flare sits at your true ...   \n4     ['High-Rise Skinny Ankle: sits above the natur...   \n...                                                 ...   \n2869                                                 []   \n2870  ['Straight-leg Jeans: straight silhouette from...   \n2871  ['Wide-leg trousers: this cut features a wide ...   \n2872                                                 []   \n2873  ['Curved Tapered: Our curved tapered jean has ...   \n\n                                            description  \\\n0     Skinny-fitting jeans made from 11.25 oz Japane...   \n1     Skinny-fitting jeans made from 11.25 oz Japane...   \n2     Straight-fitting jeans made from 320 g Japanes...   \n3     Cut for a flared, wide-leg silhouette, our Jen...   \n4     Part of our superstretch collection, these hig...   \n...                                                 ...   \n2869  SANDRO pays tribute to the artistic world of L...   \n2870                                                NaN   \n2871                                                NaN   \n2872  The Belinda jeans offer a flattering straight-...   \n2873  Made from Japanese denim, this version of Polo...   \n\n                                       style_attributes  \\\n0                                                    {}   \n1                                                    {}   \n2                                                    {}   \n3                                                    {}   \n4                                                    {}   \n...                                                 ...   \n2869  {'Composition': 'Main material: 100% cotton, S...   \n2870  {'Composition': 'Exterior: 100% cotton', 'care...   \n2871  {'Composition': 'Exterior: 50% cotton, Exterio...   \n2872  {'Fit': 'Petite', 'Care & Fabric': '100% Cotto...   \n2873                                                 {}   \n\n                                          pdp_images_s3  \n0     ['https://gallery.stylumia.com/originals/2020/...  \n1     ['https://gallery.stylumia.com/originals/2020/...  \n2     ['https://gallery.stylumia.com/originals/2020/...  \n3     ['https://gallery.stylumia.com/originals/2021/...  \n4     ['https://gallery.stylumia.com/originals/2021/...  \n...                                                 ...  \n2869  ['https://gallery.stylumia.com/originals/2025/...  \n2870  ['https://gallery.stylumia.com/originals/2025/...  \n2871  ['https://gallery.stylumia.com/originals/2025/...  \n2872  ['https://gallery.stylumia.com/originals/2025/...  \n2873  ['https://gallery.stylumia.com/originals/2025/...  \n\n[2874 rows x 19 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>selling_price</th>\n      <th>discount</th>\n      <th>category_id</th>\n      <th>meta_info</th>\n      <th>product_id</th>\n      <th>pdp_url</th>\n      <th>sku</th>\n      <th>brand</th>\n      <th>department_id</th>\n      <th>last_seen_date</th>\n      <th>launch_on</th>\n      <th>mrp</th>\n      <th>product_name</th>\n      <th>feature_image_s3</th>\n      <th>channel_id</th>\n      <th>feature_list</th>\n      <th>description</th>\n      <th>style_attributes</th>\n      <th>pdp_images_s3</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>{'USD': 285.9978}</td>\n      <td>0.000000</td>\n      <td>56</td>\n      <td>Skinny Fit: Mid-rise. Sits at the hip. Skinny ...</td>\n      <td>f4d992cf595405c44737ad1ff406360c9e7af5dc521020...</td>\n      <td>https://www.ralphlauren.co.uk/en/skinny-stretc...</td>\n      <td>398475</td>\n      <td>RALPH LAUREN</td>\n      <td>2</td>\n      <td>2025-05-15</td>\n      <td>2020-02-29</td>\n      <td>{'USD': 285.9978}</td>\n      <td>Skinny Stretch Jeans</td>\n      <td>https://gallery.stylumia.com/originals/2020/02...</td>\n      <td>14</td>\n      <td>['Skinny Fit: Mid-rise. Sits at the hip. Skinn...</td>\n      <td>Skinny-fitting jeans made from 11.25 oz Japane...</td>\n      <td>{}</td>\n      <td>['https://gallery.stylumia.com/originals/2020/...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>{'USD': 285.9978}</td>\n      <td>0.000000</td>\n      <td>56</td>\n      <td>Skinny Fit: mid-rise. Sits at the hip. Skinny ...</td>\n      <td>4c50e2a967da813d5b55452883e47ea7635e6f1972f1c9...</td>\n      <td>https://www.ralphlauren.co.uk/en/stretch-skinn...</td>\n      <td>398474</td>\n      <td>RALPH LAUREN</td>\n      <td>2</td>\n      <td>2025-05-15</td>\n      <td>2020-02-29</td>\n      <td>{'USD': 285.9978}</td>\n      <td>Stretch Skinny Jeans</td>\n      <td>https://gallery.stylumia.com/originals/2020/02...</td>\n      <td>14</td>\n      <td>['Skinny Fit: mid-rise. Sits at the hip. Skinn...</td>\n      <td>Skinny-fitting jeans made from 11.25 oz Japane...</td>\n      <td>{}</td>\n      <td>['https://gallery.stylumia.com/originals/2020/...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>{'USD': 392.4156}</td>\n      <td>0.000000</td>\n      <td>56</td>\n      <td>Boy Fit: mid-rise. Sits at the hip. Relaxed th...</td>\n      <td>2e37dd2d1b28c4df27175c39bb01f13320be5267cd7e24...</td>\n      <td>https://www.ralphlauren.co.uk/en/boy-fit-strai...</td>\n      <td>537869</td>\n      <td>RALPH LAUREN</td>\n      <td>2</td>\n      <td>2025-05-15</td>\n      <td>2020-08-13</td>\n      <td>{'USD': 392.4156}</td>\n      <td>Boy Fit Straight Jeans</td>\n      <td>https://gallery.stylumia.com/originals/2020/08...</td>\n      <td>14</td>\n      <td>['Boy Fit: mid-rise. Sits at the hip. Relaxed ...</td>\n      <td>Straight-fitting jeans made from 320 g Japanes...</td>\n      <td>{}</td>\n      <td>['https://gallery.stylumia.com/originals/2020/...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>{'USD': 170.4379}</td>\n      <td>40.174672</td>\n      <td>56</td>\n      <td>The Jenn Flare: Our flare sits at your true wa...</td>\n      <td>264387126c9841fe4bd9607926c3e6155bbefd53badbfc...</td>\n      <td>https://www.ralphlauren.co.uk/en/jenn-flare-je...</td>\n      <td>563799</td>\n      <td>RALPH LAUREN</td>\n      <td>2</td>\n      <td>2025-01-28</td>\n      <td>2021-01-17</td>\n      <td>{'USD': 284.8925}</td>\n      <td>Jenn Flare Jean</td>\n      <td>https://gallery.stylumia.com/originals/2021/01...</td>\n      <td>14</td>\n      <td>['The Jenn Flare: Our flare sits at your true ...</td>\n      <td>Cut for a flared, wide-leg silhouette, our Jen...</td>\n      <td>{}</td>\n      <td>['https://gallery.stylumia.com/originals/2021/...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>{'USD': 184.6675}</td>\n      <td>0.000000</td>\n      <td>56</td>\n      <td>High-Rise Skinny Ankle: sits above the natural...</td>\n      <td>06ebbee1d18f36444c87fd746cd7ce5ff24b943a89f0f6...</td>\n      <td>https://www.ralphlauren.co.uk/en/high-rise-ski...</td>\n      <td>561065</td>\n      <td>RALPH LAUREN</td>\n      <td>2</td>\n      <td>2025-05-01</td>\n      <td>2021-02-16</td>\n      <td>{'USD': 184.6675}</td>\n      <td>High-Rise Skinny Ankle Jean</td>\n      <td>https://gallery.stylumia.com/originals/2021/02...</td>\n      <td>14</td>\n      <td>['High-Rise Skinny Ankle: sits above the natur...</td>\n      <td>Part of our superstretch collection, these hig...</td>\n      <td>{}</td>\n      <td>['https://gallery.stylumia.com/originals/2021/...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>2869</th>\n      <td>{'USD': 420.0}</td>\n      <td>0.000000</td>\n      <td>56</td>\n      <td>Main material: 100% cotton, Secondary material...</td>\n      <td>f9fbee3a68a110f65c2dcaa01d00ed3fc787d3b367c519...</td>\n      <td>https://us.sandro-paris.com/en/p/wide-leg-stri...</td>\n      <td>d15edac77f1eadddd847303ce2ce10cf</td>\n      <td>Sandro Paris</td>\n      <td>2</td>\n      <td>2025-05-09</td>\n      <td>2025-04-30</td>\n      <td>{'USD': 420.0}</td>\n      <td>Wide-leg striped jeans</td>\n      <td>https://gallery.stylumia.com/originals/2025/04...</td>\n      <td>383</td>\n      <td>[]</td>\n      <td>SANDRO pays tribute to the artistic world of L...</td>\n      <td>{'Composition': 'Main material: 100% cotton, S...</td>\n      <td>['https://gallery.stylumia.com/originals/2025/...</td>\n    </tr>\n    <tr>\n      <th>2870</th>\n      <td>{'USD': 92.8447}</td>\n      <td>0.000000</td>\n      <td>56</td>\n      <td>Exterior: 100% cotton Composition MACHINE WASH...</td>\n      <td>a99c8e83ff86ce01228b54b0c8640d99adfca0a7755550...</td>\n      <td>https://www.massimodutti.com/gb/midrise-straig...</td>\n      <td>48640767/407</td>\n      <td>Massimo Dutti</td>\n      <td>2</td>\n      <td>2025-05-02</td>\n      <td>2025-04-30</td>\n      <td>{'USD': 92.8447}</td>\n      <td>Mid-rise straight-leg jeans</td>\n      <td>https://gallery.stylumia.com/originals/2025/04...</td>\n      <td>7</td>\n      <td>['Straight-leg Jeans: straight silhouette from...</td>\n      <td>NaN</td>\n      <td>{'Composition': 'Exterior: 100% cotton', 'care...</td>\n      <td>['https://gallery.stylumia.com/originals/2025/...</td>\n    </tr>\n    <tr>\n      <th>2871</th>\n      <td>{'USD': 79.7574}</td>\n      <td>0.000000</td>\n      <td>56</td>\n      <td>Exterior: 50% cotton, Exterior: 50% lyocell Co...</td>\n      <td>fcf79b834d61cd5ce9430a807ef218a2b9a8b5a906f309...</td>\n      <td>https://www.massimodutti.com/gb/highwaist-wide...</td>\n      <td>49228723/800</td>\n      <td>Massimo Dutti</td>\n      <td>2</td>\n      <td>2025-05-09</td>\n      <td>2025-04-30</td>\n      <td>{'USD': 79.7574}</td>\n      <td>High-waist wide-leg jeans with seam details</td>\n      <td>https://gallery.stylumia.com/originals/2025/04...</td>\n      <td>7</td>\n      <td>['Wide-leg trousers: this cut features a wide ...</td>\n      <td>NaN</td>\n      <td>{'Composition': 'Exterior: 50% cotton, Exterio...</td>\n      <td>['https://gallery.stylumia.com/originals/2025/...</td>\n    </tr>\n    <tr>\n      <th>2872</th>\n      <td>{'USD': 185.9961}</td>\n      <td>0.000000</td>\n      <td>56</td>\n      <td>Petite Fit 100% Cotton., Machine washable. Car...</td>\n      <td>05bb642a205ba1a24261cc662557cc9cdd1fc732d2664d...</td>\n      <td>https://www.reiss.com/style/su699374/h14421#h1...</td>\n      <td>H14421</td>\n      <td>Belinda</td>\n      <td>2</td>\n      <td>2025-05-01</td>\n      <td>2025-05-01</td>\n      <td>{'USD': 185.9961}</td>\n      <td>Petite Straight-Leg Turn-Up Jeans in Mid Blue</td>\n      <td>https://gallery.stylumia.com/originals/2025/05...</td>\n      <td>299</td>\n      <td>[]</td>\n      <td>The Belinda jeans offer a flattering straight-...</td>\n      <td>{'Fit': 'Petite', 'Care &amp; Fabric': '100% Cotto...</td>\n      <td>['https://gallery.stylumia.com/originals/2025/...</td>\n    </tr>\n    <tr>\n      <th>2873</th>\n      <td>{'USD': 291.3187}</td>\n      <td>0.000000</td>\n      <td>56</td>\n      <td>Curved Tapered: Our curved tapered jean has a ...</td>\n      <td>36d4b1e2e52ed98d4907c77f452416f3e15fac36c8de87...</td>\n      <td>https://www.ralphlauren.co.uk/en/curved-tapere...</td>\n      <td>100043242</td>\n      <td>RALPH LAUREN</td>\n      <td>2</td>\n      <td>2025-05-15</td>\n      <td>2025-05-01</td>\n      <td>{'USD': 291.3187}</td>\n      <td>Curved Tapered Jean</td>\n      <td>https://gallery.stylumia.com/originals/2025/05...</td>\n      <td>14</td>\n      <td>['Curved Tapered: Our curved tapered jean has ...</td>\n      <td>Made from Japanese denim, this version of Polo...</td>\n      <td>{}</td>\n      <td>['https://gallery.stylumia.com/originals/2025/...</td>\n    </tr>\n  </tbody>\n</table>\n<p>2874 rows × 19 columns</p>\n</div>"},"metadata":{}}],"execution_count":3},{"cell_type":"markdown","source":"## ✅ Verifying Column Consistency Between Datasets\n\nAfter loading the `dress` and `jeans` datasets, it's important to ensure they share the same schema — i.e., identical column names and order. This check is crucial when you plan to:\n\n- Concatenate the datasets into a single product catalog\n- Apply uniform processing or modeling pipelines\n- Perform similarity search or clustering across categories\n\n### 🔍 Code Purpose:\n```python\ndress.columns.to_list() == jeans.columns.to_list()","metadata":{}},{"cell_type":"code","source":"dress.columns.to_list() == jeans.columns.to_list()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T16:19:13.269320Z","iopub.execute_input":"2025-06-22T16:19:13.269640Z","iopub.status.idle":"2025-06-22T16:19:13.274550Z","shell.execute_reply.started":"2025-06-22T16:19:13.269614Z","shell.execute_reply":"2025-06-22T16:19:13.273837Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"## 🧩 Merging Datasets: Dresses and Jeans into One DataFrame\n\nOnce we've confirmed that both `dress` and `jeans` datasets share the same structure, we can safely combine them into a single unified DataFrame for further processing.\n\n### 🔄 Code Breakdown:\n```python\ndf = pd.concat([dress, jeans], ignore_index=True)","metadata":{}},{"cell_type":"code","source":"df = pd.concat([dress, jeans], ignore_index=True)\n# df = df.iloc[0:10, :]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T16:19:13.276523Z","iopub.execute_input":"2025-06-22T16:19:13.276725Z","iopub.status.idle":"2025-06-22T16:19:13.787201Z","shell.execute_reply.started":"2025-06-22T16:19:13.276709Z","shell.execute_reply":"2025-06-22T16:19:13.786503Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## 🧼 Cleaning Price Data and Extracting Relevant Fields\n\nThis step focuses on transforming and filtering the raw dataset to retain only the most essential information needed for modeling, recommendations, or visualization.\n\n---\n\n### 💰 Step 1: Extracting Prices from Stringified Dictionaries\n\nSome price fields (`selling_price` and `mrp`) are stored as stringified dictionaries, e.g., `\"{'INR': 1299}\"`. The goal is to extract the price in INR (or fallback to USD if INR is unavailable).\n\n```python\ndf[\"selling_price\"] = df[\"selling_price\"].apply(lambda x: eval(x).get(\"INR\") or eval(x).get(\"USD\"))\ndf[\"mrp\"] = df[\"mrp\"].apply(lambda x: eval(x).get(\"INR\") or eval(x).get(\"USD\"))","metadata":{}},{"cell_type":"code","source":"# Clean and extract required fields\n\n# Extracting the \"INR\" value from the 'selling_price' dictionary; if not present, fallback to \"USD\"\n# 'eval' is used to convert the string representation of a dictionary into an actual Python dictionary\ndf[\"selling_price\"] = df[\"selling_price\"].apply(lambda x: eval(x).get(\"INR\") or eval(x).get(\"USD\"))\n\n# Same operation for 'mrp' column to get the actual numerical price in INR or fallback to USD\ndf[\"mrp\"] = df[\"mrp\"].apply(lambda x: eval(x).get(\"INR\") or eval(x).get(\"USD\"))\n\n# Selecting and keeping only the relevant columns for further processing\n# These include identifiers, image link, product info, pricing, category, and metadata\ndf = df[[\n    \"product_id\", \"feature_image_s3\", \"product_name\", \"brand\",\n    \"description\", \"category_id\", \"style_attributes\", \"mrp\",\n    \"selling_price\", \"meta_info\"\n]]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T16:19:13.787935Z","iopub.execute_input":"2025-06-22T16:19:13.788183Z","iopub.status.idle":"2025-06-22T16:19:14.093796Z","shell.execute_reply.started":"2025-06-22T16:19:13.788159Z","shell.execute_reply":"2025-06-22T16:19:14.093173Z"}},"outputs":[],"execution_count":6},{"cell_type":"markdown","source":"## 🖼️ Downloading Product Images from URLs\n\nThis optional block of code is used to download product images from their URLs and save them locally for tasks like:\n\n- Running visual search or similarity matching\n- Building a local dataset for training image-based models\n- Creating an offline demo or image inspection interface\n\n---\n\n### 🔄 Workflow Overview:\n\n```python\n# import os, requests\n# from PIL import Image\n# from io import BytesIO","metadata":{}},{"cell_type":"code","source":"# # Image download\n# import os, requests\n# from PIL import Image\n# from io import BytesIO\n\n# os.makedirs(\"Images\", exist_ok=True)\n# for _, row in df.iterrows():\n#     try:\n#         response = requests.get(row[\"feature_image_s3\"], timeout=10)\n#         image = Image.open(BytesIO(response.content)).convert(\"RGB\")\n#         image.save(f\"Images/{row['product_id']}.jpg\")\n#     except Exception as e:\n#         print(f\"Failed for {row['product_id']}: {e}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T16:19:14.094519Z","iopub.execute_input":"2025-06-22T16:19:14.094750Z","iopub.status.idle":"2025-06-22T16:19:14.098208Z","shell.execute_reply.started":"2025-06-22T16:19:14.094724Z","shell.execute_reply":"2025-06-22T16:19:14.097608Z"}},"outputs":[],"execution_count":7},{"cell_type":"markdown","source":"## 🔐 Hugging Face Authentication using Kaggle Secrets\n\nThis block securely loads your Hugging Face token from a JSON file and logs into the Hugging Face Hub, enabling access to private or gated models and datasets.\n\n---\n\n### 🔍 Code Breakdown:\n\n```python\nimport os\nimport json\nfrom huggingface_hub import login","metadata":{}},{"cell_type":"code","source":"# Importing required libraries\nimport os  # Provides functions to interact with the operating system\nimport json  # Used to parse JSON files\nfrom huggingface_hub import login  # Used to authenticate with Hugging Face Hub\n\n# Opening and reading the Hugging Face token from a JSON file located in the input directory\nwith open(\"/kaggle/input/hf-token/hf_token.json\") as f:\n    secrets = json.load(f)  # Loading the JSON content into a Python dictionary named 'secrets'\n\n# Setting the HF_TOKEN environment variable with the token from the secrets dictionary\nos.environ[\"HF_TOKEN\"] = secrets[\"HF_TOKEN\"]\n\n# Logging into Hugging Face Hub using the loaded token\nlogin(os.environ[\"HF_TOKEN\"])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T16:19:14.098883Z","iopub.execute_input":"2025-06-22T16:19:14.099079Z","iopub.status.idle":"2025-06-22T16:19:14.859443Z","shell.execute_reply.started":"2025-06-22T16:19:14.099063Z","shell.execute_reply":"2025-06-22T16:19:14.858891Z"}},"outputs":[{"name":"stderr","text":"Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"## 🧠 CLIP-Based Image Embedding Pipeline for Fashion Products\n\nThis code cell performs the following steps to compute visual embeddings for each product image using OpenAI's CLIP model:\n\n---\n\n### Load CLIP Model and Processor\n\nWe load the `clip-vit-large-patch14` variant for high-quality image representations.\n\n- The model is moved to the selected device and set to evaluation mode.\n- The processor normalizes and resizes images as required by the model.\n\n---\n\n### Define `load_and_embed` Function\n\nThis function:\n\n- Builds the image path from the `product_id`\n- Loads and preprocesses the image\n- Uses the CLIP model to extract a 1024-dimensional image feature vector\n- Applies L2 normalization to enable cosine similarity comparisons\n- Returns the embedding or logs an error if image loading fails\n\n---\n\n### Create List of Product IDs\n\nWe extract the list of `product_id`s from the `df` DataFrame for which embeddings need to be generated.\n\n---\n\n### Multithreaded Embedding Generation\n\n- We use `ThreadPoolExecutor` to parallelize image loading and embedding (max 3 threads).\n- For each valid image, we store its normalized embedding in the `image_embeddings` dictionary using `product_id` as the key.\n\n---\n\n### Final Status Output\n\nAfter processing, we print how many product embeddings were successfully generated.\n\n✅ This setup creates a dictionary of normalized image embeddings that can be used for visual similarity search, clustering, or hybrid recommendations.\n","metadata":{}},{"cell_type":"code","source":"# Importing required libraries\nimport torch  # PyTorch for tensor computations and model inference\nfrom transformers import CLIPProcessor, CLIPModel  # Hugging Face Transformers for CLIP model and preprocessing\nfrom PIL import Image  # Python Imaging Library to handle image loading\nimport numpy as np  # For numerical operations and array manipulation\nimport os  # OS operations for file checking\nimport concurrent.futures  # For multithreaded execution to speed up embedding\nfrom tqdm.notebook import tqdm  # For progress bar in Jupyter/Kaggle notebooks\n\n# Setup device\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"  # Use GPU if available, else fallback to CPU\n\n# # Load model and processor\n# # Loading the pretrained CLIP model (ViT-Large Patch14 variant) and moving it to the selected device\n# clip_model = CLIPModel.from_pretrained(\"openai/clip-vit-large-patch14\").to(device).eval()\n\n# # Initializing the corresponding processor for CLIP to handle image preprocessing\n# clip_processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-large-patch14\", use_fast=True)\n\nfrom transformers import AutoProcessor, AutoModelForZeroShotImageClassification\n\nclip_processor = AutoProcessor.from_pretrained(\"openai/clip-vit-base-patch32\", use_fast=False)\nclip_model = AutoModelForZeroShotImageClassification.from_pretrained(\"openai/clip-vit-base-patch32\").to(device).eval()\n\n# Function to load and embed a single image\ndef load_and_embed(product_id):\n    # Construct image file path using product_id\n    image_path = f\"/kaggle/input/dataset-ecomerce/Images/Images/{product_id}.jpg\"\n    \n    # If image file doesn't exist, return None\n    if not os.path.exists(image_path):\n        return None, None\n    try:\n        # Load and convert the image to RGB format\n        image = Image.open(image_path).convert(\"RGB\")\n        \n        # Preprocess the image using CLIP processor\n        inputs = clip_processor(images=image, return_tensors=\"pt\").to(device)\n        \n        # Disable gradient calculation and extract image features\n        with torch.no_grad():\n            features = clip_model.get_image_features(**inputs)\n            \n            # Normalize the embedding vector and convert to NumPy\n            embedding = torch.nn.functional.normalize(features, p=2, dim=-1).cpu().numpy()[0]\n        \n        # Return product ID and its corresponding embedding\n        return product_id, embedding\n    except Exception as e:\n        # Handle exceptions and print error message if any image fails to process\n        print(f\"❌ Error processing {product_id}: {e}\")\n        return None, None\n\n# List of product IDs extracted from the DataFrame\nproduct_ids = df[\"product_id\"].tolist()\n\n# Dictionary to store image embeddings for each product ID\nimage_embeddings = {}\n\n# Multithreaded processing (loading + inference)\n# Using ThreadPoolExecutor to parallelize the image loading and embedding process\nwith concurrent.futures.ThreadPoolExecutor(max_workers=3) as executor:\n    results = executor.map(load_and_embed, product_ids)\n    \n    # Iterate through the results with a progress bar\n    for pid, emb in tqdm(results, total=len(product_ids)):\n        # Store the embedding if it's not None\n        if pid and emb is not None:\n            image_embeddings[pid] = emb\n\n# Print completion status with number of successfully embedded products\nprint(f\"✅ Embedding completed for {len(image_embeddings)} products.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T16:21:10.557768Z","iopub.execute_input":"2025-06-22T16:21:10.558391Z","iopub.status.idle":"2025-06-22T16:26:40.198010Z","shell.execute_reply.started":"2025-06-22T16:21:10.558369Z","shell.execute_reply":"2025-06-22T16:26:40.197429Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/17483 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d95aad6ed4fb43faafa495113ee9ce84"}},"metadata":{}},{"name":"stdout","text":"✅ Embedding completed for 17470 products.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"code","source":"len(list(image_embeddings.values())[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T16:26:42.585574Z","iopub.execute_input":"2025-06-22T16:26:42.586454Z","iopub.status.idle":"2025-06-22T16:26:42.594116Z","shell.execute_reply.started":"2025-06-22T16:26:42.586419Z","shell.execute_reply":"2025-06-22T16:26:42.593310Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"512"},"metadata":{}}],"execution_count":11},{"cell_type":"markdown","source":"## 📝 Generating Text Embeddings with SentenceTransformer\n\nThis code generates text-based semantic embeddings for each fashion product using the `all-MiniLM-L6-v2` model from the SentenceTransformers library. These embeddings capture the textual meaning of product details like name, description, and attributes, and can later be combined with image embeddings for multimodal search or recommendations.\n\n---\n\n### 🔍 Step-by-Step Explanation:\n\n1. **Load Pretrained Model**\n   - We load the `all-MiniLM-L6-v2` model using `SentenceTransformer`, which is optimized for speed and semantic similarity tasks.\n\n2. **Initialize Storage**\n   - An empty dictionary `text_embeddings` is used to store product ID → text embedding mappings.\n\n3. **Iterate Over DataFrame**\n   - For each row in the DataFrame `df`, we:\n     - Concatenate relevant text fields: `product_name`, `description`, `meta_info`, and `style_attributes` to form a descriptive input text.\n     - Print the first concatenated text example (for sanity check).\n     - Generate a 384-dimensional embedding using `text_model.encode(...)`.\n     - Store the embedding using `product_id` as the key in `text_embeddings`.\n\n4. **tqdm Progress Bar**\n   - A progress bar is displayed using `tqdm` for real-time feedback on encoding progress.\n\n---\n\n> ✅ These semantic embeddings can be used for:\n> - Text-based product search\n> - Matching similar items using text descriptions\n> - Fusing with image embeddings for hybrid retrieval systems","metadata":{}},{"cell_type":"code","source":"# Importing SentenceTransformer for generating text embeddings\nfrom sentence_transformers import SentenceTransformer\n\n# tqdm for displaying a progress bar in notebooks\nfrom tqdm.notebook import tqdm\n\n# Loading the 'all-MiniLM-L6-v2' model, a lightweight sentence embedding model from Sentence-Transformers\ntext_model = SentenceTransformer('all-MiniLM-L6-v2')\n\n# Dictionary to store the resulting text embeddings for each product\ntext_embeddings = {}\n\n# Counter to print the first example text for inspection\ni = 0\n\n# Iterating through each row in the DataFrame\nfor _, row in tqdm(df.iterrows()):\n    # Concatenating product-related text fields to form a combined input sentence\n    text = f\"{row['product_name']} {row['description']} {row['meta_info']} {row['style_attributes']}\"\n    \n    # Print the first text input to verify formatting\n    if i == 0:\n        print(text)\n    \n    i += 1  # Increment the counter\n\n    # Generating text embedding using the sentence-transformer model\n    embedding = text_model.encode(text, show_progress_bar=False)\n    \n    # Storing the embedding in the dictionary using product_id as the key\n    text_embeddings[row[\"product_id\"]] = embedding","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T16:27:25.786898Z","iopub.execute_input":"2025-06-22T16:27:25.787390Z","iopub.status.idle":"2025-06-22T16:29:36.930911Z","shell.execute_reply.started":"2025-06-22T16:27:25.787365Z","shell.execute_reply":"2025-06-22T16:29:36.930163Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"modules.json:   0%|          | 0.00/349 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"80572af42db744e4991b86d4c5413786"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config_sentence_transformers.json:   0%|          | 0.00/116 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"02461c83c5144b5cba8028e7adfac14e"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/10.5k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbd3cd6779c44d5c80a1881e3fa515a5"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentence_bert_config.json:   0%|          | 0.00/53.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0e8dcec456904105a17a959bfbc925ec"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/612 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4da6cf945997413b82c24a69c795dd4f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/90.9M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e6422a1a7d6441f854190486b9d6fda"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/350 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8381b5d5b2334687913e79ff144117b3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a5f42438ac25405d8d5fa7d08ef81dce"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f9514f1369514d3e890f90f1119c1408"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/112 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6da38dcd524a475e8881d9ca368956d4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/190 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a3cb380327914a28bf1add633d98aeb4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"0it [00:00, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c7bca4e422d148d5ae80d9a89d2a2112"}},"metadata":{}},{"name":"stdout","text":"Kristian Silk Tuxedo Dress The Kristian evening dress is informed by the tuxedo-inspired gown Mr Lauren custom-designed for Rosie Huntington-Whiteley for our 50th anniversary runway show in Central Park. Transforming a timeless pillar of menswear into the ultimate in feminine elegance, this American-made dress is realised in silk cady and distinguished by formal suiting details, such as silk-satin-covered peak lapels and buttons. Slim fit. Designed to hit at the ankle. UK size 12 has a 153 cm body length and an 84 cm sleeve length. Body length and sleeve length are taken from the centre back of the neck and change 0.5 cm between sizes. Peak lapels. Double-breasted silhouette. Silk-covered buttons. Long sleeves. Left chest welt pocket. Two front waist welt pockets. Full stretch silk lining. Shell: 100% silk. Lining: 91% silk, 9% elastane. Dry clean. Made in USA. Imported materials. Model is 1.78 m and wears a UK size 8. {}\n","output_type":"stream"}],"execution_count":13},{"cell_type":"code","source":"print(list(text_embeddings.keys())[1:10])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T16:29:36.932168Z","iopub.execute_input":"2025-06-22T16:29:36.932791Z","iopub.status.idle":"2025-06-22T16:29:36.937400Z","shell.execute_reply.started":"2025-06-22T16:29:36.932772Z","shell.execute_reply":"2025-06-22T16:29:36.936823Z"}},"outputs":[{"name":"stdout","text":"['482b10a23f8d00cfc7c9bbeeac4e26d25dd303d8e62e97ba5ba74653f80ca72e', '3508b052ef7a5eea820423b97713612bc92a3f2301a3d342f44b5cec1fe013ef', '6360245240b68885bd4dbcef8d8856c0fb13f1314769f5273904a6eac26fb452', '5d07037957e64d1e218499cb7d7a8e5e57aa59249bb8065283612dbc23260621', '1ccbcbec76de6407bc85e62549e5272d9ecd9bb770ce3bf00b1863f07425b9ed', '5972c0b7f32ec835378a787150ee7d250ddc71cab21102d9e8cf2f40619a2cea', 'be8ce31a6c52deb536c50c20c2b3c623b80aef9ae6053fc0f73ed617aea49c7c', '9ecc179568163f14f1a834185be1c9b0c0400f06deb2c8e298684dd21a63a0d4', 'c0e3f743b45a208bd2c45f80874a41d3030c48e57712238510a5e3898f700202']\n","output_type":"stream"}],"execution_count":14},{"cell_type":"markdown","source":"## 🔗 Combining Image and Text Embeddings into Unified Vectors\n\nThis step merges the previously generated visual and textual embeddings for each product into a single high-dimensional representation. This unified embedding captures both **visual appearance** and **semantic meaning**, enabling more accurate product similarity and recommendation.\n\n---\n\n### 🔍 Step-by-Step Explanation:\n\n1. **Initialize `combined_embeddings` Dictionary**  \n   A new dictionary to store the final multimodal embedding for each product, indexed by `product_id`.\n\n2. **Iterate Over Product IDs**\n   We loop through all `product_id`s in the DataFrame and:\n   - Retrieve the corresponding **image embedding** from `image_embeddings`\n   - Retrieve the corresponding **text embedding** from `text_embeddings`\n\n3. **Concatenate Image and Text Embeddings**\n   - If both embeddings are available for the product, we use `np.concatenate([...])` to combine them into a single vector.\n   - The resulting vector will be of size `512 + 384 = 896` dimensions (CLIP large image + MiniLM text).\n\n4. **Store in Dictionary**\n   - Each combined embedding is stored in `combined_embeddings` with its `product_id` as the key.\n\n---\n\n> ✅ These fused embeddings provide a rich, multimodal representation that can power hybrid search engines, personalized recommendations, or clustering algorithms.\n","metadata":{}},{"cell_type":"code","source":"# Dictionary to store combined image and text embeddings for each product\ncombined_embeddings = {}\n\n# Iterating through each product ID in the DataFrame with a progress bar\nfor pid in tqdm(df[\"product_id\"]):\n    # Retrieve image embedding for the current product ID\n    img_emb = image_embeddings.get(pid)\n\n    # Retrieve text embedding for the current product ID\n    txt_emb = text_embeddings.get(pid)\n\n    # If both embeddings are available, concatenate them into a single vector\n    if img_emb is not None and txt_emb is not None:\n        combined_embeddings[pid] = np.concatenate([img_emb, txt_emb])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T16:29:36.938104Z","iopub.execute_input":"2025-06-22T16:29:36.938381Z","iopub.status.idle":"2025-06-22T16:29:37.045103Z","shell.execute_reply.started":"2025-06-22T16:29:36.938354Z","shell.execute_reply":"2025-06-22T16:29:37.044245Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/17483 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f0c98e77d8dd43189f92afd0fa324d69"}},"metadata":{}}],"execution_count":15},{"cell_type":"markdown","source":"## 🔍 Hybrid Visual + Textual Search with CLIP and SentenceTransformer\n\nThis function enables **multi-modal similarity search** by combining image and/or text queries. It computes a unified embedding for the query, searches against a pre-built FAISS index of product embeddings, and returns the IDs of the most similar products.\n\n---\n\n### 🧠 Function: `search_similar(query_image_path=None, query_text=None, top_k=5)`\n\nThis function supports the following search modes:\n- **Image-only search** (query by example)\n- **Text-only search** (semantic keyword search)\n- **Hybrid search** (image + text fusion)\n\n---\n\n### 🧩 Steps Explained:\n\n1. **Image Embedding (`img_vec`)**\n   - If an image path is provided, the image is opened and passed through the CLIP processor and model.\n   - The resulting feature vector is extracted and converted to a NumPy array.\n   - If no image is provided, a zero vector of shape `(768,)` is used as a placeholder.\n\n2. **Text Embedding (`txt_vec`)**\n   - If a query text is provided (e.g., \"shorts with side pockets\"), it's encoded using the `SentenceTransformer` model.\n   - If not, a zero vector of shape `(384,)` is used.\n\n3. **Combine Embeddings**\n   - Both vectors are concatenated to form a single `(1408,)` vector representing the multi-modal query.\n   - The combined vector must match the dimensionality of the FAISS index (checked explicitly for safety).\n\n4. **Similarity Search with FAISS**\n   - The combined query embedding is passed to `faiss_index.search(...)`.\n   - `top_k` nearest neighbors are returned based on vector similarity (typically cosine or L2).\n\n5. **Return Results**\n   - The function returns the list of product IDs corresponding to the most similar results from the index.\n\n---\n\n### 💬 Example Usage:\n```python\nsearch_similar(\n    query_image_path='/kaggle/input/dataset-ecomerce/Images/Images/00029897a5....jpg',\n    query_text='shorts',\n    top_k=3\n)\n```\n\nThis would return the top 3 products visually and semantically similar to the given image and description.\n\n> ✅ This hybrid search approach makes your system flexible and robust — users can search using text, images, or both.\n","metadata":{}},{"cell_type":"code","source":"# Importing PIL Image class with alias to avoid conflict with torchvision's Image\nfrom PIL import Image as PILImage\n\n# Function to search for visually and textually similar products using combined embeddings\ndef search_similar(query_image_path=None, query_text=None, top_k=5):\n    # If an image path is provided, process the image\n    if query_image_path:\n        try:\n            # Load and convert the image to RGB format\n            image = PILImage.open(query_image_path).convert(\"RGB\")\n        except Exception as e:\n            # Raise an error if the image could not be loaded\n            raise ValueError(f\"Could not open image: {query_image_path} — {e}\")\n        \n        # Preprocess the image for CLIP model\n        inputs = clip_processor(images=image, return_tensors=\"pt\").to(device)\n        with torch.no_grad():\n            # Get image features using the CLIP model and convert to NumPy array\n            img_vec = clip_model.get_image_features(**inputs).cpu().numpy()[0]\n    else:\n        # If no image is provided, initialize a zero vector of the same dimension\n        img_vec = np.zeros(512, dtype=np.float32)\n    \n    # If a query text is provided, encode it using the text model\n    if query_text:\n        txt_vec = text_model.encode(query_text)\n    else:\n        # If no text is provided, use a zero vector for the text part\n        txt_vec = np.zeros(384)\n\n    # Concatenate image and text embeddings to create a single query vector\n    combined = np.concatenate([img_vec, txt_vec]).astype(\"float32\")\n\n    # Validate that the query embedding dimension matches the FAISS index dimension\n    if combined.shape[0] != faiss_index.d:\n        raise ValueError(\n            f\"Embedding dimension mismatch. Combined shape: {combined.shape} vs FAISS index dim: {faiss_index.d}\"\n        )\n\n    # Perform a similarity search on the FAISS index using the query embedding\n    D, I = faiss_index.search(np.array([combined]), top_k)\n\n    # Return the list of product IDs corresponding to the top-k nearest neighbors\n    return [ids[i] for i in I[0]]\n\n# Example usage (commented out): search for 3 items similar to both a given image and the keyword \"shorts\"\n# search_similar('/kaggle/input/dataset-ecomerce/Images/Images/00029897a53a74bd8cce87c9c6711c83fecb010497ee30cfab271060ee93fcec.jpg',\n#               'shorts',\n#               3)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T16:47:22.152331Z","iopub.execute_input":"2025-06-22T16:47:22.152698Z","iopub.status.idle":"2025-06-22T16:47:22.160690Z","shell.execute_reply.started":"2025-06-22T16:47:22.152677Z","shell.execute_reply":"2025-06-22T16:47:22.160014Z"}},"outputs":[],"execution_count":28},{"cell_type":"markdown","source":"## 👗 Outfit Recommendation via KMeans Clustering on Text Embeddings\n\nThis section groups fashion products based on their **textual semantics** and uses these clusters to recommend similar items (e.g., to complete an outfit). It enables personalized or style-aware recommendations based on product descriptions and attributes.\n\n---\n\n### 🧠 Step-by-Step Breakdown:\n\n1. **Prepare Text Embedding Matrix**\n   ```python\n   ids = list(text_embeddings.keys())\n   vectors = [text_embeddings[pid] for pid in ids]\n   text_matrix = np.array(vectors, dtype=np.float64)\n   ```\n   - Extracts all product IDs and their corresponding text embeddings.\n   - Forms a NumPy matrix `text_matrix` for clustering.\n\n2. **Fit KMeans Clustering**\n   ```python\n   kmeans = KMeans(n_clusters=15, random_state=42).fit(text_matrix)\n   ```\n   - Applies the **KMeans algorithm** to group similar product embeddings into `15` clusters.\n   - Each cluster groups products with similar semantic descriptions (e.g., similar types, styles, or use cases).\n\n3. **Assign Cluster Labels to Products**\n   ```python\n   cluster_labels = {\n       pid: kmeans.predict([np.array(text_embeddings[pid], dtype=np.float64)])[0]\n       for pid in ids\n   }\n   ```\n   - Predicts the cluster label for each product and stores it in a dictionary `cluster_labels`.\n\n4. **Define Outfit Recommendation Function**\n   ```python\n   def recommend_outfits(base_product_id, top_k=2):\n   ```\n   - Given a `base_product_id`, finds all other products in the **same semantic cluster**.\n   - Returns the first `top_k` similar products (excluding the base item).\n   - These are considered complementary or related fashion pieces (like pairing a top with a skirt or jeans with a shirt).\n\n---\n\n### 💡 Example Use Case:\n```python\nrecommend_outfits(\"000a3f4dce44e1c1e67199826dfbc672f398067a62f03fc9a7a1e8fa4bde3aa4\", top_k=2)\n```\nThis would return 2 product IDs from the same cluster as the given product, ideal for use in outfit suggestion modules.\n\n> ✅ This approach is unsupervised and scalable, making it ideal for cold-start recommendations or clustering large fashion inventories.\n> \n> ⚠️ Note: You can tune `n_clusters` to better match the number of distinct style or category types in your catalog.\n","metadata":{}},{"cell_type":"code","source":"# Importing necessary libraries\nimport numpy as np  # For numerical operations\nfrom sklearn.cluster import KMeans  # For clustering the text embeddings\n\n# Convert embeddings to matrix\n# Extract product IDs from text embeddings\nids = list(text_embeddings.keys())\n\n# Create a list of embedding vectors corresponding to each product ID\nvectors = [text_embeddings[pid] for pid in ids]\n\n# Convert the list of vectors into a NumPy array (2D matrix) for clustering\ntext_matrix = np.array(vectors, dtype=np.float64)\n\n# Fit KMeans\n# Performing KMeans clustering on the text embedding matrix with 15 clusters\nkmeans = KMeans(n_clusters=15, random_state=42).fit(text_matrix)\n\n# Predict cluster labels\n# Mapping each product ID to its predicted cluster label\ncluster_labels = {\n    pid: kmeans.predict([np.array(text_embeddings[pid], dtype=np.float64)])[0]\n    for pid in ids\n}\n\n# Function to recommend outfits based on products from the same cluster\ndef recommend_outfits(base_product_id, top_k=2):\n    # Get the cluster label for the base product\n    base_cluster = cluster_labels[base_product_id]\n    \n    # Find other products in the same cluster, excluding the base product itself\n    similar = [pid for pid in ids if cluster_labels[pid] == base_cluster and pid != base_product_id]\n    \n    # Return the top_k similar product IDs from the same cluster\n    return similar[:top_k]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T16:47:38.441882Z","iopub.execute_input":"2025-06-22T16:47:38.442700Z","iopub.status.idle":"2025-06-22T16:47:49.579731Z","shell.execute_reply.started":"2025-06-22T16:47:38.442667Z","shell.execute_reply":"2025-06-22T16:47:49.579098Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/sklearn/cluster/_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n  warnings.warn(\n","output_type":"stream"}],"execution_count":29},{"cell_type":"markdown","source":"## 👗 Extracting Fashion Trend Keywords using Gemma-3B and Web Scraping\n\nThis code leverages a powerful LLM (`Gemma-3B`) to extract **top 50 trending fashion keywords** (e.g., clothing types, styles, fabrics, silhouettes) from both:\n- Your **local product dataset (`df`)**\n- An **online fashion catalog** (via web scraping)\n\nThe result is a rich, unified string of trend keywords that can be used for:\n- Generating dynamic fashion recommendations\n- Displaying current trends in a UI\n- Filtering inventory or training models on style relevance\n\n---\n\n### 🔍 Step-by-Step Workflow\n\n---\n\n### 1. **Load Gemma-3B Model and Processor**\n```python\nmodel_id = \"google/gemma-3-4b-it\"\n```\n- Loads a 4B-parameter chat-tuned Gemma model.\n- Uses `AutoProcessor` to prepare chat-style prompts for the model.\n- Loads the model in `bfloat16` for memory efficiency, using `device_map=\"auto\"` to utilize GPU.\n\n---\n\n### 2. **Function: `extract_trend_keywords_with_gemma(description_text)`**\n- Crafts a structured system + user message prompt.\n- Instructs the model to **only extract keywords from input**, avoiding hallucinated items.\n- Asks for:\n  - Types of clothing\n  - Styles, fabrics, patterns, silhouettes\n  - Descriptive adjectives (e.g., “off-shoulder sleeveless tops”)\n  - Unique, non-repetitive English terms\n- Uses `generate()` to decode up to 300 new tokens.\n- Returns the result as a comma-separated keyword list.\n\n---\n\n### 3. **Function: `scrape_product_names(url)`**\n- Scrapes up to 5000 product names from a given fashion website (e.g., FWRD).\n- Uses `BeautifulSoup` to find product name divs and extract their clean text.\n- Acts as a source of external web data to increase trend diversity.\n\n---\n\n### 4. **Function: `get_combined_trend_string(df, use_internet=True)`**\n- Limits each product description in the dataset to 50 words.\n- Extracts trends locally using `extract_trend_keywords_with_gemma(...)`.\n- If `use_internet=True`, also:\n  - Scrapes online catalog\n  - Extracts web trends using the same Gemma model\n- Combines local + web trends into a **de-duplicated, comma-separated list** of keywords.\n\n---\n\n### ✅ Final Output\n```python\ntrend_string = get_combined_trend_string(df)\nprint(\"\\n🔥 Combined Trending Styles:\\n\", trend_string)\n```\nReturns a rich string of current fashion trends by analyzing both internal product data and external online catalogs.\n\n---\n\n> 💡 This technique ensures **trend-awareness** in your fashion system without manual labeling or static rules.\n> \n> ⚠️ Make sure to follow site scraping guidelines and respect scraping limits for public websites.\n","metadata":{}},{"cell_type":"code","source":"# Importing required libraries\nimport requests  # For making HTTP requests\nfrom bs4 import BeautifulSoup  # For parsing HTML content\nfrom transformers import AutoProcessor, Gemma3ForConditionalGeneration  # For loading Gemma model\nimport torch  # For tensor operations and model inference\n\n# Load Gemma model and processor\n# Model ID for the 4B instruction-tuned variant of Google's Gemma\nmodel_id = \"google/gemma-3-4b-it\"\n\n# Load processor to tokenize and format prompts for Gemma\ngemma_processor = AutoProcessor.from_pretrained(model_id, use_fast=True)\n\n# Load the quantized model and move to appropriate device with bfloat16 precision\ngemma_model = Gemma3ForConditionalGeneration.from_pretrained(\n    model_id,\n    torch_dtype=torch.bfloat16,\n    device_map=\"auto\"\n).eval()\n\n# 🧠 Extract 50 fashion keywords using Gemma\ndef extract_trend_keywords_with_gemma(description_text):\n    # Prompt construction using system and user roles for instruction following\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": [{\"type\": \"text\", \"text\": \"You are a fashion data analyst.\"}]\n        },\n        {\n            \"role\": \"user\",\n            \"content\": [\n                {\"type\": \"text\", \"text\":\n                    \"From the text below, extract the top 50 trending fashion-related keywords, such as Types of clothing, clothing styles, colors, fabrics, patterns, silhouettes, or themes. \"\n                    \"Avoid brand names. Return only the keywords as a comma-separated list.\\n\"\n                    \"Just give response from the given context only donot add things randomly from your side.\\n\"\n                    \"For Example if text is Silk Knit Tank Top, One shoulder top, sleevless Mini Dress, Off Shoulder Evening top, Mini tank top, Straped Off Shoulder Gown then trending cloth will be Sleevless Off shoulder tank tops. Like this we need to find trending clothes also add adjectives of clothes if present.\"\n                    \" And donot repeat the trend clothes give unique ones. And Give keywords in English only\\n\\n\"\n                    f\"{description_text}\"\n                }\n            ]\n        }\n    ]\n\n    # Convert structured message into model-readable chat prompt\n    prompt = gemma_processor.apply_chat_template(messages, add_generation_prompt=True, tokenize=False)\n\n    # Tokenize the prompt\n    tokenized = gemma_processor(text=prompt, return_tensors=\"pt\").to(gemma_model.device)\n\n    # Generate output using the model without tracking gradients\n    with torch.no_grad():\n        output = gemma_model.generate(\n            input_ids=tokenized[\"input_ids\"],\n            attention_mask=tokenized[\"attention_mask\"],\n            max_new_tokens=300\n        )\n\n    # Decode the model's response, skipping special tokens\n    response = gemma_processor.decode(output[0][tokenized[\"input_ids\"].shape[-1]:], skip_special_tokens=True)\n    return response.strip()\n\n# Function to scrape product names from a fashion retail webpage\ndef scrape_product_names(url, max_items=5000):\n    headers = {\"User-Agent\": \"Mozilla/5.0\"}  # Set user agent to mimic a browser\n    \n    try:\n        # Fetch and parse the HTML content\n        response = requests.get(url, headers=headers, timeout=30)\n        soup = BeautifulSoup(response.content, \"html.parser\")\n\n        # Extract product names from specific div classes\n        name_divs = soup.find_all(\"div\", class_=\"product-grids__copy-item js-plp-name\")\n        names = [div.get_text(strip=True) for div in name_divs]\n\n        # Limit the number of items returned\n        return names[:max_items]\n    \n    except Exception as e:\n        # Catch and print any errors during scraping\n        print(f\"❌ Error: {e}\")\n        return []\n\n# 🧠 Final function to get combined trends\ndef get_combined_trend_string(df, use_internet=True):\n    # Inner function to limit number of words per description\n    def limit_words(text, max_words=50):\n        return \" \".join(text.split()[:max_words])\n\n    # Extract and clean description texts from DataFrame\n    descriptions = df[\"description\"].dropna().astype(str).tolist()\n    limited_descriptions = [limit_words(desc) for desc in descriptions[:100]]  # Limit to first 100 entries\n    local_text = \"\\n\".join(limited_descriptions)\n\n    # Generate fashion keywords using local data\n    local_trends = extract_trend_keywords_with_gemma(local_text)\n    print(\"🧵 Local Trends:\", local_trends)\n\n    # If enabled, scrape website and generate additional keywords\n    if use_internet:\n        url = \"https://www.fwrd.com/fw/content/products/lazyLoadProductsForward?currentPlpUrl=https%3A%2F%2Fwww.fwrd.com%2Ffwpage%2Fcategory-clothing%2F3699fc%2F&currentPageSortBy=featuredF&useLargerImages=false&outfitViewSession=false&showBagSize=false&lookfwrd=false&backinstock=false&preorder=false&_=1749445996960\"\n        web_text = scrape_product_names(url)\n        web_trends = extract_trend_keywords_with_gemma(web_text)\n        print(\"🌐 Web Trends:\", web_trends)\n    else:\n        web_trends = \"\"\n\n    # Combine both local and web trend lists\n    combined_keywords = set(local_trends.split(\",\") + web_trends.split(\",\"))\n    \n    # Clean and sort the final list of unique keywords\n    combined_clean = [kw.strip() for kw in combined_keywords if kw.strip()]\n    return \", \".join(sorted(combined_clean))\n\n# ✅ Usage\n# Call function to extract combined trending fashion keywords from both local and web sources\ntrend_string = get_combined_trend_string(df)\nprint(\"\\n🔥 Combined Trending Styles:\\n\", trend_string)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T16:47:49.581178Z","iopub.execute_input":"2025-06-22T16:47:49.581540Z","iopub.status.idle":"2025-06-22T17:13:27.787161Z","shell.execute_reply.started":"2025-06-22T16:47:49.581504Z","shell.execute_reply":"2025-06-22T17:13:27.786299Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/accelerate/utils/modeling.py:1569: UserWarning: Current model requires 33282 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a9cda2d9312c42f9a9d3765fdd289078"}},"metadata":{}},{"name":"stdout","text":"🧵 Local Trends: dress, shirtdress, midi dress, mini dress, flow dress, sweater dress, knit dress, silk dress, satin dress, jersey dress, crepe dress, tweed dress, floral dress, printed dress, ruffled dress, pleated dress, flared dress, sheath dress, A-line dress, fit-and-flare dress, wrap dress, bodycon dress, shirtdress, dress, gown, maxi dress, mini dress, shirt dress, midi dress\n🌐 Web Trends: Embroidery, Mini Dress, Maxi Dress, Tank Top, Dress, Skirt, Top, Pant, Gown, Sweater, Shirt, Vest, Jacket, Legging, Bodysuit, Bra, Shorts, Sleeve, Halter, Spaghetti Strap, Off Shoulder, Lace, Knit, Denim, Silk, Cotton, Linen, Jersey, Stripe, Floral, Animal Print, Ruched, Pleated, A-line, Bell-sleeve, Crewneck, Fitted, Maxi, Midi, Mini, Long Sleeve, Short Sleeve, Crop Top, Button-down, Wrap, Puffer, Trench Coat, Cardigan, Sweatshirt, Blouse\n\n🔥 Combined Trending Styles:\n A-line, A-line dress, Animal Print, Bell-sleeve, Blouse, Bodysuit, Bra, Button-down, Cardigan, Cotton, Crewneck, Crop Top, Denim, Dress, Embroidery, Fitted, Floral, Gown, Halter, Jacket, Jersey, Knit, Lace, Legging, Linen, Long Sleeve, Maxi, Maxi Dress, Midi, Mini, Mini Dress, Off Shoulder, Pant, Pleated, Puffer, Ruched, Shirt, Short Sleeve, Shorts, Silk, Skirt, Sleeve, Spaghetti Strap, Stripe, Sweater, Sweatshirt, Tank Top, Top, Trench Coat, Vest, Wrap, bodycon dress, crepe dress, dress, dress, fit-and-flare dress, flared dress, floral dress, flow dress, gown, jersey dress, knit dress, maxi dress, midi dress, mini dress, pleated dress, printed dress, ruffled dress, satin dress, sheath dress, shirt dress, shirtdress, silk dress, sweater dress, tweed dress, wrap dress\n","output_type":"stream"}],"execution_count":30},{"cell_type":"markdown","source":"## 👤 Summarizing User Fashion Preferences from Interaction History\n\nThis function analyzes a user’s interaction history and summarizes their preferences in terms of:\n- **Top Brands**\n- **Preferred Styles**\n- **Common Product Descriptions**\n\nIt helps personalize recommendations, outfit suggestions, or display a style profile.\n\n---\n\n### 🧠 Function: `summarize_user_preferences(user_id, df, history_dict, top_k=5)`\n\n---\n\n### 🔍 Step-by-Step Explanation:\n\n1. **Nested Function: `clean_style_attr(style_attr)`**\n   - Handles inconsistent formats in the `style_attributes` field.\n   - If it's a dictionary, flattens it into a readable string (`\"fit: slim, sleeve: full\"`).\n   - If it's a string, strips whitespace.\n   - Returns `\"Unknown\"` for unexpected types.\n\n2. **Retrieve User History**\n   ```python\n   pids = history_dict.get(user_id, [])\n   rows = df[df[\"product_id\"].isin(pids)]\n   ```\n   - Looks up the product IDs the user interacted with from `history_dict`.\n   - Filters the dataset to get all matching rows.\n\n3. **Handle Empty History**\n   - If no products are found for the user, return `\"No Brands\"`, `\"No Styles\"`, and `\"No Description\"`.\n\n4. **Extract Top Brands**\n   ```python\n   brands = rows[\"brand\"].dropna().astype(str).value_counts().index.tolist()[:top_k]\n   ```\n   - Counts the most frequent brands and returns the top `k`.\n\n5. **Extract Top Style Attributes**\n   ```python\n   styles_cleaned = rows[\"style_attributes\"].apply(clean_style_attr)\n   styles = styles_cleaned.value_counts().index.tolist()[:top_k]\n   ```\n   - Applies the cleaner to each style attribute and selects the most common ones.\n\n6. **Extract Descriptive Summary**\n   ```python\n   descriptions = rows[\"meta_info\"].dropna().astype(str).tolist()\n   merged_desc = \" \".join(descriptions[:top_k * 2]) if descriptions else \"No Description\"\n   ```\n   - Concatenates up to `2 * top_k` product descriptions to build a rough summary of user interests.\n\n7. **Return Summary**\n   ```python\n   return \", \".join(brands), \", \".join(styles), merged_desc\n   ```\n   - Returns the user's **preferred brands**, **style types**, and **sample descriptive text**.\n\n---\n\n### 📌 Usage Example:\n```python\nbrands, styles, summary = summarize_user_preferences(user_id=\"user_42\", df=df, history_dict=user_history)\nprint(\"👕 Brands:\", brands)\nprint(\"🎨 Styles:\", styles)\nprint(\"📝 Summary:\", summary)\n```\n\n> ✅ This function enables **personalized recommendations** and profile generation for any fashion user by leveraging historical behavior.\n","metadata":{}},{"cell_type":"code","source":"# Function to summarize a user's fashion preferences based on their viewing or purchase history\ndef summarize_user_preferences(user_id, df, history_dict, top_k=5):\n    \n    # Helper function to clean and format the 'style_attributes' field\n    def clean_style_attr(style_attr):\n        if isinstance(style_attr, dict):\n            # Convert dictionary to a comma-separated key-value string\n            return \", \".join(f\"{k}: {v}\" for k, v in style_attr.items())\n        elif isinstance(style_attr, str):\n            # Strip whitespace if it's a plain string\n            return style_attr.strip()\n        else:\n            # Handle missing or unknown format\n            return \"Unknown\"\n\n    # Get list of product IDs associated with the given user\n    pids = history_dict.get(user_id, [])\n\n    # Filter DataFrame to include only rows matching those product IDs\n    rows = df[df[\"product_id\"].isin(pids)]\n\n    # If no matching rows found, return default placeholders\n    if rows.empty:\n        return \"No Brands\", \"No Styles\", \"No Description\"\n\n    # Extract and clean top brands based on frequency\n    brands = rows[\"brand\"].dropna().astype(str).value_counts().index.tolist()[:top_k]\n\n    # Clean style attributes and get most frequent ones\n    styles_cleaned = rows[\"style_attributes\"].apply(clean_style_attr)\n    styles = styles_cleaned.value_counts().index.tolist()[:top_k]\n\n    # Combine top meta_info descriptions into a single string\n    descriptions = rows[\"meta_info\"].dropna().astype(str).tolist()\n    merged_desc = \" \".join(descriptions[:top_k * 2]) if descriptions else \"No Description\"\n\n    # Return summarized user preferences\n    return \", \".join(brands), \", \".join(styles), merged_desc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T17:13:27.788138Z","iopub.execute_input":"2025-06-22T17:13:27.788942Z","iopub.status.idle":"2025-06-22T17:13:27.796192Z","shell.execute_reply.started":"2025-06-22T17:13:27.788921Z","shell.execute_reply":"2025-06-22T17:13:27.795512Z"}},"outputs":[],"execution_count":31},{"cell_type":"code","source":"df['meta_info'].isna().sum()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T17:13:27.797793Z","iopub.execute_input":"2025-06-22T17:13:27.798046Z","iopub.status.idle":"2025-06-22T17:13:27.816734Z","shell.execute_reply.started":"2025-06-22T17:13:27.798016Z","shell.execute_reply":"2025-06-22T17:13:27.816002Z"}},"outputs":[{"execution_count":32,"output_type":"execute_result","data":{"text/plain":"71"},"metadata":{}}],"execution_count":32},{"cell_type":"markdown","source":"## ⚡ Building a FAISS Index for Fast Similarity Search\n\nThis section creates a **FAISS (Facebook AI Similarity Search)** index from the combined (image + text) embeddings of all products. The index enables **real-time nearest neighbor search** to support features like:\n\n- Visual + text-based product retrieval\n- Hybrid similarity recommendations\n- Style or trend-aware fashion matching\n\n---\n\n### 🧠 Step-by-Step Explanation:\n\n---\n\n### Step 1: Prepare Embedding Matrix\n```python\nids = list(combined_embeddings.keys())\nvectors = np.stack([combined_embeddings[pid] for pid in ids]).astype(\"float32\")\n```\n- Extracts all product IDs and their corresponding 1408-dimensional combined embeddings.\n- Converts them into a NumPy array of shape `(N, 1408)` where `N` is the number of products.\n- Casts to `float32`, the required format for FAISS.\n\n---\n\n### Step 2: Initialize and Build FAISS Index\n```python\nfaiss_index = faiss.IndexFlatL2(vectors.shape[1])\nfaiss_index.add(vectors)\n```\n- **`IndexFlatL2`**: A fast, brute-force FAISS index using **L2 (Euclidean) distance**.\n  - Ideal for small to medium-scale datasets where accuracy is more important than speed.\n- Adds all vectors to the index for later querying.\n\n---\n\n### 📌 Notes:\n- The dimension must match the combined embedding size: `1024 (image) + 384 (text) = 1408`.\n- This index can now be used with:\n  ```python\n  faiss_index.search(query_vector, top_k)\n  ```\n  to retrieve the top `k` most similar products.\n\n> ✅ FAISS enables scalable, low-latency vector search across thousands or millions of fashion items.\n> \n> 🧠 You can switch to `IndexIVFFlat` or `IndexHNSWFlat` for approximate search in large-scale deployments.\n","metadata":{}},{"cell_type":"code","source":"# Importing necessary libraries\nimport faiss  # Facebook AI Similarity Search for fast nearest neighbor retrieval\nimport numpy as np  # For numerical operations\n\n# Step 1: Create vectors\n# Extract product IDs from the combined_embeddings dictionary\nids = list(combined_embeddings.keys())\n\n# Stack all combined embeddings into a 2D NumPy array of shape (n_samples, 1408)\n# Each row corresponds to a product's [image + text] embedding\nvectors = np.stack([combined_embeddings[pid] for pid in ids]).astype(\"float32\")\n\n# Step 2: Create a new FAISS index (use correct dim = 1408)\n# Create a flat L2 (Euclidean distance) index with dimensionality matching the embedding size\nfaiss_index = faiss.IndexFlatL2(vectors.shape[1])\n\n# Add all product vectors to the FAISS index for similarity search\nfaiss_index.add(vectors)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T17:13:27.817594Z","iopub.execute_input":"2025-06-22T17:13:27.817894Z","iopub.status.idle":"2025-06-22T17:13:27.966125Z","shell.execute_reply.started":"2025-06-22T17:13:27.817854Z","shell.execute_reply":"2025-06-22T17:13:27.965581Z"}},"outputs":[],"execution_count":33},{"cell_type":"code","source":"len(list(combined_embeddings.values())[0])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T17:13:27.966794Z","iopub.execute_input":"2025-06-22T17:13:27.966985Z","iopub.status.idle":"2025-06-22T17:13:27.971830Z","shell.execute_reply.started":"2025-06-22T17:13:27.966969Z","shell.execute_reply":"2025-06-22T17:13:27.971294Z"}},"outputs":[{"execution_count":34,"output_type":"execute_result","data":{"text/plain":"896"},"metadata":{}}],"execution_count":34},{"cell_type":"code","source":"512 + 384 # text_embeddings + image_embeddings","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T17:13:27.972577Z","iopub.execute_input":"2025-06-22T17:13:27.972812Z","iopub.status.idle":"2025-06-22T17:13:27.983977Z","shell.execute_reply.started":"2025-06-22T17:13:27.972790Z","shell.execute_reply":"2025-06-22T17:13:27.983182Z"}},"outputs":[{"execution_count":35,"output_type":"execute_result","data":{"text/plain":"896"},"metadata":{}}],"execution_count":35},{"cell_type":"markdown","source":"## *🧠 Personalized Outfit Suggestions using Gemma-3B and Multimodal Prompting*\n\nThis function utilizes the **Gemma-3B Instruction-Tuned** model from Google to generate **personalized and visually-aware outfit suggestions**. It combines the uploaded product image, product metadata, user preference history, and trend signals to simulate an expert fashion stylist's response.\n\n---\n\n### 🧩 Key Components:\n\n1. **Model Initialization**\n   - Loads `gemma-3-4b-it`, an instruction-tuned LLM capable of understanding structured prompts and multimodal inputs.\n   - The processor formats image + text into a chat-compatible structure.\n   - The model runs on GPU with `bfloat16` precision using `device_map=\"auto\"`.\n\n2. **Function: `generate_outfit_gemma(...)`**\n\n#### 🔍 Inputs:\n- `image_path`: Path to the product image\n- `row`: A row from the product DataFrame containing all metadata\n- `user_id`: The user for whom personalized suggestions are generated\n- `number_of_suggestions`: Number of outfit pieces to be recommended\n\n---\n\n### 🧵 Prompt Construction\n\nA structured multimodal prompt is created with the following components:\n\n- **Image**: Shown to the model via PIL (converted to RGB)\n- **Product Metadata**: Includes name, brand, style attributes, description, and price\n- **User Preferences**: Top brands, style features, and liked descriptions from past activity\n- **Trend Context**: A precomputed list of trending styles (e.g., \"off-shoulder tops\", \"cropped denim\")\n\nThe model is asked to:\n- Suggest `n` matching outfit items\n- Justify each recommendation briefly\n- Format the response as a clean bullet list\n- Avoid questions or irrelevant output\n\n---\n\n### ⚙️ Model Inference\n\n- The `messages` list is passed through `apply_chat_template()` to produce the formatted input.\n- Tokenized inputs are sent to the model for generation (`max_new_tokens=700`).\n- The final output is decoded, trimmed, and returned as a user-ready stylist response.\n\n---\n\n### ✅ Output\n\nReturns a stylized and structured list of outfit suggestions such as:\n```\n- Cropped white blazer – Adds structure to the soft silhouette while keeping the look modern.\n- Gold layered necklaces – Accentuate the neckline and align with user’s preference for elegant accessories.\n```\n\n> 📌 This function is central to building an **Intelligent Styling Assistant**, combining **vision, text, personalization, and generative AI**.\n","metadata":{}},{"cell_type":"code","source":"# Import required libraries for model loading and image processing\nfrom transformers import AutoProcessor, Gemma3ForConditionalGeneration  # Hugging Face tools for the Gemma model\nfrom PIL import Image as PILImage  # PIL for image loading\nimport torch  # PyTorch for tensor manipulation and inference\n\n# Define the model ID for the instruction-tuned version of Gemma\nmodel_id = \"google/gemma-3-4b-it\"\n\n# Load the processor for formatting inputs to the model\ngemma_processor = AutoProcessor.from_pretrained(model_id, use_fast=True)\n\n# Load the Gemma model using bfloat16 precision and automatic device placement\ngemma_model = Gemma3ForConditionalGeneration.from_pretrained(\n    model_id,\n    torch_dtype=torch.bfloat16,  # use float16 if bfloat16 is unsupported\n    device_map=\"auto\"\n).eval()\n\n# Function to generate outfit suggestions based on a product image and user preferences\ndef generate_outfit_gemma(image_path, row, user_id=\"user123\", number_of_suggestions=5):\n    # Get summarized user preferences (brands, styles, and descriptions)\n    user_brands, user_styles, user_description = summarize_user_preferences(user_id, df, user_history, top_k=3)\n\n    # Refined Prompt\n    messages = [\n        {\n            \"role\": \"system\",\n            \"content\": [{\"type\": \"text\", \"text\": \"You are a highly experienced fashion stylist and personal shopper.\"}]\n        },\n        {\n            \"role\": \"user\",\n            \"content\": [\n                # Image input to condition the generation\n                {\"type\": \"image\", \"image\": PILImage.open(image_path).convert(\"RGB\")},\n\n                # Textual prompt combining product info, user style preferences, and trending styles\n                {\"type\": \"text\", \"text\":\n                    \"Using the image above and the following product and user profile information, \"\n                    f\"please suggest {number_of_suggestions} specific and stylish outfit items that would complement this product perfectly.\\n\\n\"\n\n                    \"🎯 **Product Details**:\\n\"\n                    f\"- **Name**: {row['product_name']}\\n\"\n                    f\"- **Brand**: {row['brand']}\\n\"\n                    f\"- **Style Attributes**: {row['style_attributes']}\\n\"\n                    f\"- **Description**: {row['description']}\\n\"\n                    f\"- **Price**: ₹{row['selling_price']}\\n\\n\"\n\n                    \"🧍‍♀️ **User Style Preferences**:\\n\"\n                    f\"- **Favorite Brands**: {user_brands}\\n\"\n                    f\"- **Preferred Style Features**: {user_styles}\\n\"\n                    f\"- **Liked Descriptions**: {user_description}\\n\\n\"\n\n                    \"🔥 **Trending Styles Right Now**:\\n\"\n                    f\"{trend_string}\\n\\n\"\n\n                    \"💡 Provide specific clothing or accessory suggestions that:\\n\"\n                    \"- Match both the product’s style and user's preferences\\n\"\n                    \"- Reflect the current trends\\n\"\n                    \"- Include a short reason for each suggestion\\n\\n\"\n                    \n                    \"Format your answer as a bullet list with names and explanations and also just give response don't ask any further question.\"\n                }\n            ]\n        }\n    ]\n\n    # Format input for Gemma\n    inputs = gemma_processor.apply_chat_template(\n        messages,\n        add_generation_prompt=True,\n        tokenize=True,\n        return_dict=True,\n        return_tensors=\"pt\"\n    ).to(gemma_model.device)  # Move input tensors to model device\n\n    input_len = inputs[\"input_ids\"].shape[-1]  # Capture input length to slice model output later\n\n    # Generate model response without gradient tracking\n    with torch.no_grad():\n        outputs = gemma_model.generate(**inputs, max_new_tokens=700)\n        response = gemma_processor.decode(outputs[0][input_len:], skip_special_tokens=True)\n\n    return response  # Return the final generated outfit suggestions","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T17:13:27.985007Z","iopub.execute_input":"2025-06-22T17:13:27.985347Z","iopub.status.idle":"2025-06-22T17:13:35.696147Z","shell.execute_reply.started":"2025-06-22T17:13:27.985326Z","shell.execute_reply":"2025-06-22T17:13:35.695597Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/accelerate/utils/modeling.py:1569: UserWarning: Current model requires 33282 bytes of buffer for offloaded layers, which seems does not fit any GPU's remaining memory. If you are experiencing a OOM later, please consider using offload_buffers=True.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Loading checkpoint shards:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3f1b1234250b4f5596b21cdd16c6a3f2"}},"metadata":{}}],"execution_count":36},{"cell_type":"markdown","source":"## *🛍️ Full Pipeline: Fashion Visual Search + Personal Styling Assistant*\n\nThis section brings together all core components of the fashion intelligence system and simulates a real-world user session. It performs **visual search, user preference modeling, outfit generation**, and **text-only inventory exploration** — all within a cohesive, interactive loop.\n\n---\n\n### 🧩 Step-by-Step Workflow:\n\n---\n\n### 1. **Seed User History from Images**\n- A list of file IDs (`file_ids`) simulates browsing behavior.\n- Each image is passed through `search_similar()` to retrieve the top visually similar product.\n- These retrieved `product_id`s are added to `user_history[\"user123\"]`.\n\n---\n\n### 2. **Summarize User Style Profile**\n```python\nsummarize_user_preferences(user_id, df, user_history)\n```\n- Extracts user's favorite **brands**, **style attributes**, and **descriptions** based on their viewed history.\n- Used to condition LLM-based outfit generation.\n\n---\n\n### 3. **Set Final Query Image & Text**\n- A target image is selected to represent a final product of interest.\n- A free-text query (e.g., `\"just looking for mini shorts\"`) mimics how users refine their intent.\n\n---\n\n### 4. **Visual + Text Similarity Search**\n```python\nsearch_similar(query_image_path=eval_image, query_text=text_query, top_k=10)\n```\n- Retrieves visually and semantically similar items from the FAISS index.\n- Displays them with product name, brand, and price.\n\n---\n\n### 5. **Generate AI-Based Outfit Suggestions**\n```python\ngenerate_outfit_gemma(image_path, row, user_id, number_of_suggestions)\n```\n- Combines:  \n  - The query product’s image  \n  - Product metadata  \n  - User preference profile  \n  - Real-time fashion trend string  \n- Uses Gemma-3B to generate 5 personalized outfit components with explanations.\n\n---\n\n### 6. **Text-Only Inventory Search**\n```python\nsearch_similar(query_text=text_query)\n```\n- Allows retrieval of products **without uploading an image**, ideal for mobile/web users or voice-based input.\n\n---\n\n### 7. **Cluster-Based Personalized Recommendations**\n```python\nrecommend_outfits(base_product_id, top_k)\n```\n- Recommends stylistically similar items from the same KMeans cluster as the top match.\n- Tailors suggestions based on unsupervised style grouping from your dataset.\n\n---\n\n### ✅ Output Summary:\n- 🔍 Visually + semantically similar product list\n- 🧠 AI-generated outfit items tailored to user style and current trends\n- 🧾 Search results for user-entered fashion queries\n- 📦 Personalized recommendations based on user cluster\n\n> 💡 This complete pipeline showcases how to build a **real-time, intelligent fashion recommendation engine** using image + text + trends + user data — powered by multimodal retrieval and generative AI.\n","metadata":{}},{"cell_type":"code","source":"# Importing display tools and image handling libraries\nfrom IPython.display import display, Markdown, Image as ColabImage  # For displaying images and markdown in notebooks\nfrom PIL import Image as PILImage  # PIL for opening and manipulating images\nimport os  # OS operations (e.g., path handling)\nimport gc  # Python garbage collector for memory cleanup\nimport torch  # PyTorch for tensor operations\n\n# Base directory of images in the dataset\nbase_dir = \"/kaggle/input/dataset-ecomerce/Images/Images/\"\n\n# Filenames only\n# A manually curated list of image filenames from the dataset, possibly used for demo, testing, or fixed visual samples\nfile_ids = [\n    \"001cc7734a6ded96796a018bbc477f2c02c591b349276d0cba02aa2ff5ac5643.jpg\",\n    \"d2375eda5a1e7d3b70928f62f5d5544b4acbac3066b3ce81b69054f94a4b4699.jpg\",\n    \"2d79fbf8a8d16367fb50a2d901ce156dcbf9d576cefd416a5704d9ce56c1a163.jpg\", \n    \"f51af2ef89785fc6bb9022e51638473b4c9d5502cdc1d646f6174ac2230a7dda.jpg\",\n    \"7200c1cc52432f6162f49450d11b8aaa0fb20c7d4bdecaf78221724ef4e65842.jpg\", # Pant\n    \"cf4929378f6df845c0586297e187ba83d0233132eb16ea5ef8e725a561dca350.jpg\",\n    \"3912d625079ca4451b69f8bf05b49a366d18a5d19ccc66927ddfe8472b7e238c.jpg\",\n    \"5bb24d735d0d883b74d54eca4259cda99d33b1b2276a8af368f8ed0b74434dbc.jpg\",\n    \"41124e644edefe8f62183e4e272b0e1875b25f27a6921db1fd18f04227d28f33.jpg\",\n    \"6ae3eab605f8fce59bac14c9683967e2a92b2810e0f5ad628770de1ed2c89335.jpg\",\n    \"1f8858ffec5e9bb3080efd79a897f1c29b107331a727a025d9656bb159d1c210.jpg\",\n    \"b9a31680489fd7d86c4e63db69f478d88ec29c94c7c14e1c6194bfb2f22dc451.jpg\", \n    \"a679c7224741a85a360c15433d3270b274ad2be6762964a3016de5e2cf977396.jpg\",\n    \"2bfd2ecf2b3dcb0456f38e90d8eac7959a86d62bf391196052d716558ca3892a.jpg\",\n    \"50b9e4c78cd22ccd2f51749f005933e225ec28745677c763bae9db6a1df0c699.jpg\",\n    \"3b95bcf6ee388620dbefc4b157b3062b8817f5c58300d4dad5085f53788b07a4.jpg\",\n    \"004eb122c5f855688d88bc67e1040b68649ebf006a524847381899af841106a2.jpg\", # only dress\n    \"f47545349516bd64e6a235b7433618a7d56a89b9a314b8dd2b5559cb97ab5927.jpg\", # only dress\n    \"a326c2ebae5f65dc52df9ef9cbe0174b7a6d0eebb6ef113031c6fa17d716e87e.jpg\",\n    \"80e1cec6743c039088e55dc972614c004e084214878eb77263a8bf31d81abf7a.jpg\",\n    \"d71430db83e8a11f846346898ea7f8dd96417a8c0e329ed9e1947f498105b427.jpg\",\n    \"ae8e6b75dd7cdc91028c52a21da3a893addef0b6a26331b706be37edb6cffa7c.jpg\",\n    \"6ad111071f0abd165ffb969e884143053af793a08b0ec5cfd7bbb336756076a9.jpg\",\n    \"004e598c1e8b7f6960d98e18c72f672ad51213fba53daed642226a1a0beeb6ba.jpg\",\n    \"1ea243e3fe3adb01f636837f4a0508c4e5fd0105ede18b1a6dbcc4833cd3754b.jpg\",\n    \"e6dd290aa9ccf67afbcfafda532a780dd399cedd11b8609418512b55e57ffd8a.jpg\",\n    \"48c364ae27afe5c90d18f034b54939b64b81e1edc2f9c39477cd39517d70de74.jpg\",\n    \"fb269300b89a93ca40e4852b5538cb55c69b2d7210630c4534e80fc418875d66.jpg\",\n    \"6f049551f8254f207ba91307cac602b4dd4f59bb9ea752531b782bfee143592b.jpg\",\n    \"f98b809c263a7afcf9599af980dd001afa2d455993bdcea406655d88fb8c2ddb.jpg\",\n    \"23ba3751946b5c1aeb2c26ecee35dbd110f77034912cceec37793b2582c2d249.jpg\",\n    \"e32cdcaa1cc0bb2c45d7c87af5b4bfc9cbac9f3e2cfdab6d82d5068219dbc094.jpg\",\n    \"b021027979aa958c026cbb6a7aafe3fe142d8c7e9146eba6effc092f155b76e8.jpg\",\n    \"da95d235d355966b809f0d2a5565e2c44deecfd272908862196676e0da70cf37.jpg\",\n    \"7c89760ba9ce4067d12e867ac43b53dbbc2930b5cbbb2e18705ba1b8f361de13.jpg\",\n    \"7a762dedfa44e60e1827412d6ea1a583a0784ff8390d49261651f0bb7b5248b7.jpg\",\n    \"e50759c449086b3b1b5ce74c2387af27719cee7f3c8f9c7898e864f80557154e.jpg\",\n    \"76f7d48b979291b2bd59ad50b9b9f0d91aa7313c79b0664c1c3d8e9bff64d9ca.jpg\",\n    \"1363a3681f397ec57fe076589a761a5527da8647551c06d3adb19875c62bccc4.jpg\",\n    \"ca35331d6e4ab68e4ef28fca64f32b532dc29bc91b83d31257b8f5c1cc1f591a.jpg\",\n    \"33eab84b80f35180bb7d28de928749093ffeaee000ecefb2a1aa9abe12b5d3d4.jpg\",\n    \"106ea31260ca214d881d99b5add1cede7368c0dc3a14bae47ed7b200563539b2.jpg\",\n    \"d19183e13cca52fdecb11c71b35689cb31ded1e10ec9a8813ea63ef4c66e04c1.jpg\", # Pant\n    \"b03cdf3521c8aaadc9bbb220a27d637938b623e00ba6f7b228544c7cfaeb4503.jpg\",\n    \"4065bdeaf7d6383b531c3bdb98e0fff8a5da18fe9b51c024a8ade189de9d5694.jpg\",\n    \"70e40a189be184226083b19a9d7f78bd0ad04bb77dd2311ae410992ffb80c5f4.jpg\",\n    \"1dd2334c0934cb3d3d77bfa89edf95744a726b7885ab4e1dc82a740f7252b434.jpg\",\n    \"f11de4958958cd329871f79b24800cbaf9ca5e9ba7519d239c65cfff17c690f9.jpg\",\n    \"7df2df33cbbe2465ab0d6bd9328edb35ddce05ad2116a3d96a5050f08ab47628.jpg\",\n    \"59508ef2f9cc0a3e52071e12616a78e71c6e0f9786eec00435a0eff1f97cb3f0.jpg\",\n    \"25d3c9f71e66be484e659a15c68ca6c54b1227fc038eda66a0aff2ba6e5dbd79.jpg\",\n    \"d2b9ad7636a9861cd3987719c1b93f78d0aa295c799f71139decc9fc10930d6c.jpg\",\n    \"532c1a5b7076eea7910de17c3360505dab1a54d762dae1e39f57897fa63a019e.jpg\",\n    \"07211beaef746d5fb44bae6904afa700f290ff2c259124a49c2995f26a4a3642.jpg\",\n    \"77a0a0be70b306aee1d77dfe8f45a421bd9fab024c057c3f4a761c8544aa5ed9.jpg\",\n]\n\n# Initialize history\n# Creating a dictionary to track product interaction history for a specific user\n# This will be used to personalize recommendations later\nuser_history = {\"user123\": []}\n\n# Step 1: Fill user history from seed images\n# Iterating over the list of sample image filenames to simulate user browsing history\nfor file_id in file_ids:\n    full_path = os.path.join(base_dir, file_id)  # Construct full image path\n    print(f\"\\n📥 Browsing: {full_path}\")\n    try:\n        # Search visually similar product using only image (text query is empty here)\n        results = search_similar(full_path, query_text=\"\", top_k=1)\n        for pid in results:\n            # If the product exists in the dataset, add it to the user's history\n            if pid in df[\"product_id\"].values:\n                user_history[\"user123\"].append(pid)\n            else:\n                # Skip unknown product IDs that may not exist in the DataFrame\n                print(f\"⚠️ Skipping unknown product_id: {pid}\")\n    except Exception as e:\n        # Handle failures (e.g., unreadable image file or inference error)\n        print(f\"❌ Failed to process {file_id}: {e}\")\n\n# Step 2: Summarize user preferences\n# Extract top 5 brands, styles, and description tokens from the user’s browsing history\nbrands, styles, desc = summarize_user_preferences(\"user123\", df, user_history, top_k=5)\nprint(\"\\n🧍‍♀️ User Preference Summary:\")\nprint(f\"Brands: {brands}\")\nprint(f\"Styles: {styles}\")\nprint(f\"Description Summary: {desc}\")\n\n# Step 3: Final evaluation with query image\n# Multiple image paths provided for evaluation; only one is active at a time\n# Final image to use for visual query + text query\n\n# eval_image = \"/kaggle/input/dataset-ecomerce/Images/Images/00086378cb48ebe15ed73d4ce4bc54cbe813cf13d2c8e1b31dcb9e2570aff771.jpg\"\n# eval_image = \"/kaggle/input/dataset-ecomerce/Images/Images/dc97bca7bd1adfc74d1d0e77d4adfe96d064aa98b5505a2985fdacf2c6e9bec9.jpg\" # pant\n# eval_image = \"/kaggle/input/dataset-ecomerce/Images/Images/5d01f17ecba0cd84b368f0776c43aee94b23dedce3d37de9244c512abf6f1814.jpg\" \n# eval_image = \"/kaggle/input/dataset-ecomerce/Images/Images/d2afb90fef7c4a9cbd95df9c9a139141b319dba0aa90c342aec592eca25aba40.jpg\" \n# eval_image = \"/kaggle/input/dataset-ecomerce/Images/Images/affad4a2a4fb56ca087361e3dc72fb17f6c579ded0751e6e9e45263524ae6596.jpg\" \n# eval_image = \"/kaggle/input/dataset-ecomerce/Images/Images/788e92783fb7fe6230bbf000c7f6f89321f2be4cad2eb5d8e3fa16ac203c5969.jpg\" \n# eval_image = \"/kaggle/input/dataset-ecomerce/Images/Images/ba805b1b37e2e3d2373017902660416c568ae8629a3aa5af88a0c2216d27a77b.jpg\" \neval_image = \"/kaggle/input/dataset-ecomerce/Images/Images/ddf5723e1553ce6c5840545e5876208e5013135fba4f52b87fc76933f768ed7a.jpg\" \n# eval_image = \"/kaggle/input/dataset-ecomerce/Images/Images/7594c9b2adcf5d0aad971af4d361b1cc77dcc5703506011d2ca96c4a0254116d.jpg\" \ntext_query = \"just looking for mini shorts\"\nprint(f\"\\n🎯 Final Query Image: {eval_image}\")\n\n# Step 4: Visually similar items\n# Retrieve top-10 visually + textually similar products using FAISS search\nsimilar_pids = search_similar(eval_image, query_text=text_query, top_k=10)\nprint(\"\\n🔍 Step 1: Visually Similar Products\")\nfor pid in similar_pids:\n    row = df[df[\"product_id\"] == pid].iloc[0]  # Get product info row\n    image_url = row[\"feature_image_s3\"]  # URL to display image from S3\n    display(ColabImage(url=image_url))  # Show product image\n    print(f\"{row['product_name']}\")\n    print(f\"Brand: {row['brand']} | Price: ₹{row['selling_price']}\\n\")\n\n# Step 5: Outfit suggestion (LLaVA on top-1)\nprint(\"\\n🧠 Step 2: Outfit Suggestions using Vision-Language Model\")\ntop_pid = similar_pids[0]  # Take the top-1 most similar product\ntop_row = df[df[\"product_id\"] == top_pid].iloc[0]  # Fetch corresponding row\n\ntry:\n    # Generate personalized outfit suggestions using Gemma model\n    outfit_suggestions = generate_outfit_gemma(eval_image, top_row, user_id=\"user123\", number_of_suggestions=5)\nexcept Exception as e:\n    # Handle model generation error\n    outfit_suggestions = f\"❌ Error generating outfit suggestions: {e}\"\n\n# Display outfit recommendations in Markdown format\ndisplay(Markdown(f\"**🧠 Suggested Items to Complete Your Outfit:**\\n\\n{outfit_suggestions}\"))\n\n# Step 6: Text-Only Search (e.g., user types what they want)\nprint(\"\\n🧾 Step 4: Inventory Search Based on Text Query Only\")\n\n# Perform similarity search using only the text query, no image\ntext_only_results = search_similar(query_image_path=None, query_text=text_query, top_k=10)\n\n# Display the search results from inventory\nfor pid in text_only_results:\n    if pid in df[\"product_id\"].values:\n        row = df[df[\"product_id\"] == pid].iloc[0]\n        image_url = row[\"feature_image_s3\"]\n        display(ColabImage(url=image_url))\n        print(f\"{row['product_name']}\")\n        print(f\"Brand: {row['brand']} | Price: ₹{row['selling_price']}\\n\")\n    else:\n        print(f\"⚠️ Skipping unknown product_id: {pid}\")\n\n# Step 7: Cluster-based suggestions from user history\nprint(\"\\n📦 Step 3: Personalized Recommendations Based on Your Style History\")\n# Recommend products from the same style cluster as the top match\nhistory_recs = recommend_outfits(top_pid, top_k=10)\n\n# Display the personalized cluster-based recommendations\nfor pid in history_recs:\n    if pid in df[\"product_id\"].values:\n        row = df[df[\"product_id\"] == pid].iloc[0]\n        image_url = row[\"feature_image_s3\"]\n        display(ColabImage(url=image_url))\n        print(f\"{row['product_name']}\")\n        print(f\"Brand: {row['brand']} | Price: ₹{row['selling_price']}\\n\")\n    else:\n        print(f\"⚠️ Skipping unknown product_id: {pid}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T17:13:35.697882Z","iopub.execute_input":"2025-06-22T17:13:35.698099Z","iopub.status.idle":"2025-06-22T17:22:36.209061Z","shell.execute_reply.started":"2025-06-22T17:13:35.698083Z","shell.execute_reply":"2025-06-22T17:22:36.208232Z"}},"outputs":[{"name":"stdout","text":"\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/001cc7734a6ded96796a018bbc477f2c02c591b349276d0cba02aa2ff5ac5643.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/d2375eda5a1e7d3b70928f62f5d5544b4acbac3066b3ce81b69054f94a4b4699.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/2d79fbf8a8d16367fb50a2d901ce156dcbf9d576cefd416a5704d9ce56c1a163.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/f51af2ef89785fc6bb9022e51638473b4c9d5502cdc1d646f6174ac2230a7dda.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/7200c1cc52432f6162f49450d11b8aaa0fb20c7d4bdecaf78221724ef4e65842.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/cf4929378f6df845c0586297e187ba83d0233132eb16ea5ef8e725a561dca350.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/3912d625079ca4451b69f8bf05b49a366d18a5d19ccc66927ddfe8472b7e238c.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/5bb24d735d0d883b74d54eca4259cda99d33b1b2276a8af368f8ed0b74434dbc.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/41124e644edefe8f62183e4e272b0e1875b25f27a6921db1fd18f04227d28f33.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/6ae3eab605f8fce59bac14c9683967e2a92b2810e0f5ad628770de1ed2c89335.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/1f8858ffec5e9bb3080efd79a897f1c29b107331a727a025d9656bb159d1c210.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/b9a31680489fd7d86c4e63db69f478d88ec29c94c7c14e1c6194bfb2f22dc451.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/a679c7224741a85a360c15433d3270b274ad2be6762964a3016de5e2cf977396.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/2bfd2ecf2b3dcb0456f38e90d8eac7959a86d62bf391196052d716558ca3892a.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/50b9e4c78cd22ccd2f51749f005933e225ec28745677c763bae9db6a1df0c699.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/3b95bcf6ee388620dbefc4b157b3062b8817f5c58300d4dad5085f53788b07a4.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/004eb122c5f855688d88bc67e1040b68649ebf006a524847381899af841106a2.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/f47545349516bd64e6a235b7433618a7d56a89b9a314b8dd2b5559cb97ab5927.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/a326c2ebae5f65dc52df9ef9cbe0174b7a6d0eebb6ef113031c6fa17d716e87e.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/80e1cec6743c039088e55dc972614c004e084214878eb77263a8bf31d81abf7a.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/d71430db83e8a11f846346898ea7f8dd96417a8c0e329ed9e1947f498105b427.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/ae8e6b75dd7cdc91028c52a21da3a893addef0b6a26331b706be37edb6cffa7c.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/6ad111071f0abd165ffb969e884143053af793a08b0ec5cfd7bbb336756076a9.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/004e598c1e8b7f6960d98e18c72f672ad51213fba53daed642226a1a0beeb6ba.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/1ea243e3fe3adb01f636837f4a0508c4e5fd0105ede18b1a6dbcc4833cd3754b.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/e6dd290aa9ccf67afbcfafda532a780dd399cedd11b8609418512b55e57ffd8a.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/48c364ae27afe5c90d18f034b54939b64b81e1edc2f9c39477cd39517d70de74.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/fb269300b89a93ca40e4852b5538cb55c69b2d7210630c4534e80fc418875d66.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/6f049551f8254f207ba91307cac602b4dd4f59bb9ea752531b782bfee143592b.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/f98b809c263a7afcf9599af980dd001afa2d455993bdcea406655d88fb8c2ddb.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/23ba3751946b5c1aeb2c26ecee35dbd110f77034912cceec37793b2582c2d249.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/e32cdcaa1cc0bb2c45d7c87af5b4bfc9cbac9f3e2cfdab6d82d5068219dbc094.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/b021027979aa958c026cbb6a7aafe3fe142d8c7e9146eba6effc092f155b76e8.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/da95d235d355966b809f0d2a5565e2c44deecfd272908862196676e0da70cf37.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/7c89760ba9ce4067d12e867ac43b53dbbc2930b5cbbb2e18705ba1b8f361de13.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/7a762dedfa44e60e1827412d6ea1a583a0784ff8390d49261651f0bb7b5248b7.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/e50759c449086b3b1b5ce74c2387af27719cee7f3c8f9c7898e864f80557154e.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/76f7d48b979291b2bd59ad50b9b9f0d91aa7313c79b0664c1c3d8e9bff64d9ca.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/1363a3681f397ec57fe076589a761a5527da8647551c06d3adb19875c62bccc4.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/ca35331d6e4ab68e4ef28fca64f32b532dc29bc91b83d31257b8f5c1cc1f591a.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/33eab84b80f35180bb7d28de928749093ffeaee000ecefb2a1aa9abe12b5d3d4.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/106ea31260ca214d881d99b5add1cede7368c0dc3a14bae47ed7b200563539b2.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/d19183e13cca52fdecb11c71b35689cb31ded1e10ec9a8813ea63ef4c66e04c1.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/b03cdf3521c8aaadc9bbb220a27d637938b623e00ba6f7b228544c7cfaeb4503.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/4065bdeaf7d6383b531c3bdb98e0fff8a5da18fe9b51c024a8ade189de9d5694.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/70e40a189be184226083b19a9d7f78bd0ad04bb77dd2311ae410992ffb80c5f4.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/1dd2334c0934cb3d3d77bfa89edf95744a726b7885ab4e1dc82a740f7252b434.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/f11de4958958cd329871f79b24800cbaf9ca5e9ba7519d239c65cfff17c690f9.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/7df2df33cbbe2465ab0d6bd9328edb35ddce05ad2116a3d96a5050f08ab47628.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/59508ef2f9cc0a3e52071e12616a78e71c6e0f9786eec00435a0eff1f97cb3f0.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/25d3c9f71e66be484e659a15c68ca6c54b1227fc038eda66a0aff2ba6e5dbd79.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/d2b9ad7636a9861cd3987719c1b93f78d0aa295c799f71139decc9fc10930d6c.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/532c1a5b7076eea7910de17c3360505dab1a54d762dae1e39f57897fa63a019e.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/07211beaef746d5fb44bae6904afa700f290ff2c259124a49c2995f26a4a3642.jpg\n\n📥 Browsing: /kaggle/input/dataset-ecomerce/Images/Images/77a0a0be70b306aee1d77dfe8f45a421bd9fab024c057c3f4a761c8544aa5ed9.jpg\n\n🧍‍♀️ User Preference Summary:\nBrands: Reformation, By Anthropologie, PAIGE, Good American, AGOLDE\nStyles: {}, {'Color Code': '001', 'Style No.': '4130079370007'}, {'Color Code': '029', 'Style No.': '4145593580010'}, {'Color Code': '010', 'Style No.': '97541106'}, {'Material': '97% COTTON, 3% ELASTANE, 100% POLYAMIDE, 100% POLYESTER', 'Care': 'MACHINE WASH AT MAX.TEMP. 30° C - NORMAL PROCESS, DO NOT BLEACH, DO NOT TUMBLE DRY, IRON AT MAX. TEMP. OF 110° C WITHOUT STEAM, DO NOT DRY CLEAN'}\nDescription Summary: non-adjustable straps, halter neckline. lined, not sheer. Designed to have a relaxed fit throughout. Mid-thigh length for most customers 5'4\"-5'8\". This is a lightweight drapey crepe fabric with a dry hand feel, made from 53% Viscose, 47% LENZING™  ECOVERO™ Viscose. Dry clean only. The model is wearing a size 0 and is 5'8\", 23\" waist, 35.5\" hips, 30\" bust.   The model is wearing a size 0 and is 5'8\", 23\" waist, 35.5\" hips, 30\" bust.   This is a lightweight drapey crepe fabric with a dry hand feel, made from 53% Viscose, 47% LENZING™  ECOVERO™ Viscose. Dry clean only. scoop neckline.  Designed to be fitted at bodice with a full skirt. This is a soft, non-stretch velvet with a medium pile - 82% rayon, 18% silk. Dry clean only. The model is wearing a size 2 and is 5'11\", 26\" waist, 38\" hips, 35\" bust.   The model is wearing a size 2 and is 5'11\", 26\" waist, 38\" hips, 35\" bust.   This is a soft, non-stretch velvet with a medium pile - 82% rayon, 18% silk. Dry clean only. non-adjustable straps, boat neckline. belt not included.  Designed to be fitted at bodice with an A-line skirt. Customers say this style runs true to size. This is a soft, non-stretch velvet with a medium pile - 82% rayon, 18% silk. Dry clean only. The model is wearing a size 0 and is 5'9\", 24\" waist, 34\" hips, 31\" bust.   The model is wearing a size 0 and is 5'9\", 24\" waist, 34\" hips, 31\" bust.   This is a soft, non-stretch velvet with a medium pile - 82% rayon, 18% silk. Dry clean only. scoop neckline. side zipper.  Designed to be fitted throughout. This is a Deadstock Fabric made from 51% Polyester, 37% Rayon and 12% Spandex. Wash cold + dry flat. The model is wearing a size XS and is 5'10\", 24\" waist, 35\" hips, 31\" bust.   The model is wearing a size XS and is 5'10\", 24\" waist, 35\" hips, 31\" bust.   This is a Deadstock Fabric made from 51% Polyester, 37% Rayon and 12% Spandex. Wash cold + dry flat. collared neckline.  Designed to be fitted at waist and hips with an A-line skirt. This is a non-stretch denim fabric made with 80% Organically Grown Cotton and 20% Recycled Cotton. Wash cold + line dry. The model is wearing a size 0 and has a 23\" waist, 34\" hips.   The model is wearing a size 0 and has a 23\" waist, 34\" hips.   This is a non-stretch denim fabric made with 80% Organically Grown Cotton and 20% Recycled Cotton. Wash cold + line dry. 001 Color Code 4130079370007 Style No. Polyester Tie straps Pullover styling Dry clean Imported 029 Color Code 4145593580010 Style No. 59% cotton, 41% acrylic Fitted mini silhouette Halter neckline Crochet knit Hand wash Imported 010 Color Code 97541106 Style No. 100% polyester Relaxed fit V-neckline Pullover styling Hand wash Imported 97% COTTON, 3% ELASTANE, 100% POLYAMIDE, 100% POLYESTER Material MACHINE WASH AT MAX.TEMP. 30° C - NORMAL PROCESS, DO NOT BLEACH, DO NOT TUMBLE DRY, IRON AT MAX. TEMP. OF 110° C WITHOUT STEAM, DO NOT DRY CLEAN Care round neck long sleeves cut off waist 001 Color Code 4142926610085 Style No. Cotton Pullover styling Hand wash Imported\n\n🎯 Final Query Image: /kaggle/input/dataset-ecomerce/Images/Images/ddf5723e1553ce6c5840545e5876208e5013135fba4f52b87fc76933f768ed7a.jpg\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"42a58a916e234d428354d0366f4ef7b7"}},"metadata":{}},{"name":"stdout","text":"\n🔍 Step 1: Visually Similar Products\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2025/01/48/ddf5723e1553ce6c5840545e5876208e5013135fba4f52b87fc76933f768ed7a.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"LSPACE Ringside Mini Dress\nBrand: LSPACE | Price: ₹13041.975\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2025/01/48/ecd26813d36911bfa67ae436dd9b938bdaf6457630c109c034380b47bf808c51.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"LSPACE Kelsey Mini Dress\nBrand: LSPACE | Price: ₹10233.3455\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2024/07/48/6b36759662f616897ee15cc4f8cb136337b08c192666da4e44d2361ce57c7220.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"LSPACE Corsica Strapless Cutout Midi Dress\nBrand: LSPACE | Price: ₹11915.9746\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2024/07/48/618af8836c94974ede38c62985906a939b0685ad5b801ad2037bb450bb216100.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"BHLDN Deco Square-Neck Mini Dress\nBrand: BHLDN | Price: ₹25364.4333\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2025/03/48/01ab49e139986aa693b00086629d5f8e17a9c1ec8040ddad28afeb4db72961c0.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"BHLDN Sleeveless Lace Fit & Flare Mini Dress\nBrand: BHLDN | Price: ₹22117.4205\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2023/02/48/e50759c449086b3b1b5ce74c2387af27719cee7f3c8f9c7898e864f80557154e.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"AGOLDE Parker Denim Long Shorts\nBrand: AGOLDE | Price: ₹148.0\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2024/04/48/2fe904ff153040def166fb521eeda26c3fddb0f355c31cea51020f5386eb1749.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"LSPACE Calla Midi Dress\nBrand: LSPACE | Price: ₹11915.9746\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2024/02/18/72777dcc745dbc8d8457d8779ddb0babee4068cd6d389db306cf7ac2ce847bba.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"Lovella Linen Dress\nBrand: Reformation | Price: ₹7895.9541\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2023/06/48/87c72c9227c91e0b0a0368cc4ba9455ea361edd633c63fda5d8a3dada261fee0.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"Sundays Tara Dress\nBrand: Sundays | Price: ₹13663.32\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2025/03/48/db9f83b6664d4782bdac16c2b67f19e86ff19a73586f79464675181b7e28a612.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"Forever That Girl Airy Babydoll Mini Dress\nBrand: Forever That Girl | Price: ₹12687.5125\n\n\n🧠 Step 2: Outfit Suggestions using Vision-Language Model\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**🧠 Suggested Items to Complete Your Outfit:**\n\nHere are 5 outfit items that would complement the LSPACE Ringside Mini Dress, considering the user's preferences and current trends:\n\n*   **Reformation Olivia Slip Dress (Color: Ivory)** -  This slip dress in a similar ivory hue would create a beautiful monochromatic look with the mini dress, aligning with Reformation’s brand aesthetic and the user's preference for a clean, minimalist style. The slip dress offers a luxurious feel, complementing the crepe fabric of the mini dress.\n\n*   **By Anthropologie Bell Sleeve Cardigan (Color: Dusty Rose)** - A dusty rose bell sleeve cardigan adds a touch of romanticism and warmth. The bell sleeves fit within the user's favorite style features (like the halter neckline of the mini dress) and would create a sophisticated layered look. \n\n*   **PAIGE High-Waisted Skinny Jeans (Color: Light Wash Denim)** -  Pairing the mini dress with light wash, high-waisted skinny jeans is a current trend that offers a chic contrast. The denim complements the dress’s lightness and creates a versatile, effortless outfit perfect for casual outings.\n\n*   **Sam Edelman Stevie Pointed-Toe Flats (Color: Blush)** - These flats are a sleek and comfortable option, aligning with the user’s fondness for polished footwear. Blush is a neutral that will work well with the ivory dress and add a feminine touch. \n\n*   **A Animal Print Scarf (Color: Leopard Print)** - Adding a delicate leopard print scarf tied loosely around the neck adds a playful pop of color and texture, embracing the current trend of animal prints while remaining within the user’s style preferences for sophisticated, elevated pieces."},"metadata":{}},{"name":"stdout","text":"\n🧾 Step 4: Inventory Search Based on Text Query Only\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e547139db3b642db8d96de9c63ae8cb3"}},"metadata":{}},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2025/02/383/1433b1905e22f82030325def54e03b60671026cd5f96009855856de782eb4b28.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"Denim shorts\nBrand: Sandro Paris | Price: ₹182.0\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2023/02/48/e50759c449086b3b1b5ce74c2387af27719cee7f3c8f9c7898e864f80557154e.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"AGOLDE Parker Denim Long Shorts\nBrand: AGOLDE | Price: ₹148.0\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2024/09/367/aebd9314231aa7de063f8013bec9d4d86673d4fba809ddff903b957529859804.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"Petite Compact Stretch Waist Tab Detail Tailored Mini Dress\nBrand: KarenMillen | Price: ₹8766.8194\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2024/09/367/b6fee675e313c67d1ed1d945894b43453fa1e62488b60f94fd44d7efe629cca7.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"Petite Compact Stretch Waist Tab Detail Tailored Mini Dress\nBrand: KarenMillen | Price: ₹13367.2806\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2024/02/367/df5e82e036e08dbed71cee16e97c1f86f632a4c6b198afd02709083adf86617e.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"Petite Compact Stretch Waist Tab Detail Tailored Mini Dress\nBrand: KarenMillen | Price: ₹8772.7626\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2024/06/12/c4872ec1461e30ae7ac0b6aa83b8c28f54558a6b0b988ff7b0dc2cc29b65ae4c.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"PLEATED MINI TUNIC DRESS\nBrand: COS | Price: ₹10519.7752\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2024/07/12/3fca4c893467743988b6864821043873e01b2ae7745932beccf16de2a5e9c113.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"PLEATED MINI TUNIC DRESS\nBrand: COS | Price: ₹10519.7752\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2023/09/160/05ee132fa1ca540209ddc921e1df9e3f32802b4e7ed0a6dbc107a79be82f411b.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"long-sleeved pleated minidress\nBrand: JIL SANDER | Price: ₹164700.613\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2024/07/367/a2b03c717cad6a74cc4db3561491ef1798797f5e0ca1e62e2c3cd40113f2df0e.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"Petite Soft Tailored Crepe Tab Detail Pleated Mini Dress\nBrand: KarenMillen | Price: ₹6458.1044\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2024/03/367/835d947bd868ce48885c9867d22b7553a159f84a0621636df2020b2de699d202.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"Petite Compact Stretch One Shoulder Pleated Waist Mini Dress\nBrand: KarenMillen | Price: ₹6342.3996\n\n\n📦 Step 3: Personalized Recommendations Based on Your Style History\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2021/10/48/e45633f0b85f2cf1b1aad6c509994be7f4e7c028d25668f34274174e398365ee.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"Sweaty Betty Explorer Midi Dress\nBrand: Sweaty Betty | Price: ₹10766.8292\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2022/04/48/dd1ce082765e5d22f45c3a9ff96e13cd9bff4d44a6d9763bffcc635266e03487.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"Peixoto Parker Tie Midi Dress\nBrand: Peixoto | Price: ₹13587.131\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2022/05/48/f9abefa3151c7c341694f4a35a55a246e715d5fc7c7e6885f8238b66181fe7be.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"Beyond Yoga Featherweight At The Ready Square-Neck Midi Dress\nBrand: BEYOND YOGA | Price: ₹11867.241\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2022/05/48/295b69fcfa3e5902628d72e52310af0d172649faf79389a420fbdee786333128.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"PQ Victoria Maxi Dress\nBrand: PQ Swim | Price: ₹13243.153\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2022/07/48/067058caa572bd645b4dbc7edf5d66951916e2d43de18ffbf9e76be573a2c773.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"Sundays Shawn Mini Dress\nBrand: sundays | Price: ₹12157.969\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2022/07/48/1d1e53cd4f44cd899d1957d5d413edc922ce5406475dc87590d0a45f5fa4a4dd.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"Hanky Panky Retro Chemise\nBrand: hanky panky | Price: ₹7629.6528\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2022/12/48/14e563e6c2118a9894a8108687938a52856f717d9dd50b6ce153fb5a0dfffe8f.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"Sundays Tara Dress\nBrand: Sundays | Price: ₹13716.2298\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2023/02/48/e4129933d91f51ac55721a7e4cd70f9bf0a01a1bf3661ef69ae6e785c33ddf8f.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"Eberjey Mademoisella Chemise\nBrand: Eberjey | Price: ₹10972.9838\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2023/02/48/e20e890fc6b345645d0f1f79568e2f04a261fb37041ceaf81ddbbd32acbccac5.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"Eberjey Summer Of Love Elba Cover-Up Dress\nBrand: Eberjey | Price: ₹12469.0813\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/html":"<img src=\"https://gallery.stylumia.com/originals/2023/02/48/0b6f9a093a231e9c035de6fabc595097762045a2a6bcbf1315b673b45911fa1e.jpg\"/>","text/plain":"<IPython.core.display.Image object>"},"metadata":{}},{"name":"stdout","text":"Peixoto Serena Dress\nBrand: Peixoto | Price: ₹16973.8343\n\n","output_type":"stream"}],"execution_count":37},{"cell_type":"markdown","source":"## 💾 Saving All Models Locally for Deployment or Reuse\n\nTo ensure fast reloading and offline compatibility, this step saves all key models and processors used in the system to the local working directory.\n\n---\n\n### 🔐 1. Save CLIP Model and Processor\n```python\nclip_model.save_pretrained(\"clip-vit-large-patch14\")\nclip_processor.save_pretrained(\"clip-vit-large-patch14\")\n```\n- Saves the **CLIP visual encoder** (`clip-vit-large-patch14`) and its associated image processor to a folder named after the model.\n- Enables reuse in future sessions or deployment to inference environments.\n\n---\n\n### ✍️ 2. Save SentenceTransformer Text Model\n```python\ntext_model.save(\"all-MiniLM-L6-v2\")\n```\n- Saves the **text embedding model** (`all-MiniLM-L6-v2`) used for semantic understanding of product descriptions, styles, and queries.\n\n---\n\n### 🧠 3. Save Gemma LLM and Processor\n```python\ngemma_model.save_pretrained(\"gemma-3-4b-it\")\ngemma_processor.save_pretrained(\"gemma-3-4b-it\")\n```\n- Saves the **Gemma-3B instruction-tuned model** and its processor for generating personalized outfit recommendations.\n- Useful for loading the same model in production or fine-tuning scenarios.\n\n---\n\n### ✅ Final Confirmation\n```python\nprint(\"✅ All models saved locally in current working directory.\")\n```\n- Confirms that all three core models have been persisted successfully.\n\n> 📦 These saved models can now be uploaded to Hugging Face, integrated into APIs, or bundled in a Streamlit/HF Spaces app.\n","metadata":{}},{"cell_type":"code","source":"# # === 1. Save CLIP Model and Processor ===\n# # Save the CLIP vision-language model to a local directory for reuse or deployment\n# clip_model.save_pretrained(\"clip-vit-large-patch14\")\n# # Save the associated processor (handles image + text preprocessing)\n# clip_processor.save_pretrained(\"clip-vit-large-patch14\")\n\n# # === 2. Save SentenceTransformer Model ===\n# # Save the text embedding model (MiniLM) locally for future loading without internet\n# text_model.save(\"all-MiniLM-L6-v2\")\n\n# # === 3. Save Gemma Model and Processor ===\n# # Save the multimodal Gemma model to the local filesystem\n# gemma_model.save_pretrained(\"gemma-3-4b-it\")\n# # Save the processor used to tokenize and format Gemma inputs\n# gemma_processor.save_pretrained(\"gemma-3-4b-it\")\n\n# # Confirmation message\n# print(\"✅ All models saved locally in current working directory.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T17:22:36.210051Z","iopub.execute_input":"2025-06-22T17:22:36.210378Z","iopub.status.idle":"2025-06-22T17:22:36.214109Z","shell.execute_reply.started":"2025-06-22T17:22:36.210352Z","shell.execute_reply":"2025-06-22T17:22:36.213375Z"}},"outputs":[],"execution_count":38},{"cell_type":"markdown","source":"## 💾 Save & Load All Fashion Assistant Assets (Models, Embeddings, Indexes)\n\nThis section defines utility functions to **persist and reload** all key components of the fashion visual search and recommendation system, including:\n\n- Image, text, and combined embeddings\n- FAISS index for vector similarity search\n- User history and trend strings\n- Product metadata and cluster labels\n\nThis enables checkpointing, deployment, or sharing the pipeline across environments (local or cloud).\n\n---\n\n### 🧠 Function: `save_all_assets(...)`\n\nSaves all the following components to a specified folder (`Assets/` by default):\n\n#### ✅ Embeddings\n- **`image_embeddings.pkl`**: Dict of image vectors by `product_id`\n- **`text_embeddings.pkl`**: Dict of text vectors by `product_id`\n- **`combined_vectors.npy`**: NumPy array of all combined vectors\n- **`product_ids.pkl`**: List of product IDs used for indexing\n\n#### 🔍 FAISS Index\n- **`faiss_index.index`**: Saved similarity search index built from combined vectors\n\n#### 📄 Metadata and User State\n- **`product_metadata_df.pkl`**: Pandas DataFrame of the entire product catalog\n- **`user_history.pkl`**: Dict of user → product_id history\n- **`trend_string.pkl`**: Precomputed string of trending fashion keywords\n- **`cluster_labels.pkl`**: Dict of product_id → KMeans cluster label\n\nThis ensures you can fully resume the session or deploy to another environment without recomputation.\n\n---\n\n### 🔁 Function: `load_all_assets(...)`\n\nReads all saved files and restores the following components into memory:\n\n- Embedding dictionaries (`image_embeddings`, `text_embeddings`)\n- Combined embedding matrix and product ID list\n- FAISS index (`faiss_index`)\n- Product metadata DataFrame\n- User interaction history (`user_history`)\n- Fashion trend string (`trend_string`)\n- Cluster labels from KMeans\n\n---\n\n### 🧪 Final Check\n\nAfter loading, we confirm the loaded asset integrity:\n```python\nprint(f\"Combined vector dimension: {combined_vectors.shape[1]}\")\nprint(f\"FAISS index dimension: {faiss_index.d}\")\nprint(f\"Trend string:\\n{trend_string[:300]}...\")\n```\nThis validates that the saved data is correctly restored and compatible with the search pipeline.\n\n---\n\n> ✅ These functions are essential for deploying the system in production, caching training results, or packaging the app for platforms like Hugging Face Spaces or Streamlit.\n","metadata":{}},{"cell_type":"code","source":"# Import required libraries\nimport os, pickle, json  # For file I/O operations and serialization\nimport numpy as np  # For handling numerical arrays\n\n# Function to save all necessary components to disk\ndef save_all_assets(\n    image_embeddings,\n    text_embeddings,\n    combined_embeddings,\n    faiss_index,\n    df,\n    user_history,\n    trend_string,\n    cluster_labels,\n    save_dir=\"Assets\"\n):\n    os.makedirs(save_dir, exist_ok=True)  # Create the save directory if it doesn't exist\n\n    # Save image embeddings to a pickle file\n    with open(os.path.join(save_dir, \"image_embeddings.pkl\"), \"wb\") as f:\n        pickle.dump(image_embeddings, f)\n\n    # Save text embeddings to a pickle file\n    with open(os.path.join(save_dir, \"text_embeddings.pkl\"), \"wb\") as f:\n        pickle.dump(text_embeddings, f)\n\n    # Save the product IDs used in combined embeddings\n    with open(os.path.join(save_dir, \"product_ids.pkl\"), \"wb\") as f:\n        pickle.dump(list(combined_embeddings.keys()), f)\n\n    # Save the actual combined embedding vectors as a .npy file\n    np.save(os.path.join(save_dir, \"combined_vectors.npy\"), np.stack([combined_embeddings[pid] for pid in combined_embeddings]))\n\n    # Save the FAISS index for fast similarity search\n    faiss.write_index(faiss_index, os.path.join(save_dir, \"faiss_index.index\"))\n\n    # Save the full product metadata DataFrame\n    df.to_pickle(os.path.join(save_dir, \"product_metadata_df.pkl\"))\n\n    # Save user history (dictionary) as pickle\n    with open(os.path.join(save_dir, \"user_history.pkl\"), \"wb\") as f:\n        pickle.dump(user_history, f)\n\n    # Save the trend string (fashion keywords) as a pickle\n    with open(os.path.join(save_dir, \"trend_string.pkl\"), \"wb\") as f:\n        pickle.dump(trend_string, f)\n\n    # Save the cluster labels (product_id to cluster mapping)\n    with open(os.path.join(save_dir, \"cluster_labels.pkl\"), \"wb\") as f:\n        pickle.dump(cluster_labels, f)\n\n    print(\"✅ All embeddings, metadata, user history, and trend string saved.\")\n\n# Function to load all previously saved assets from disk\ndef load_all_assets(load_dir=\"Assets\"):\n    with open(os.path.join(load_dir, \"image_embeddings.pkl\"), \"rb\") as f:\n        image_embeddings = pickle.load(f)\n\n    with open(os.path.join(load_dir, \"text_embeddings.pkl\"), \"rb\") as f:\n        text_embeddings = pickle.load(f)\n\n    with open(os.path.join(load_dir, \"product_ids.pkl\"), \"rb\") as f:\n        ids = pickle.load(f)\n\n    # Load combined vectors and FAISS index\n    combined_vectors = np.load(os.path.join(load_dir, \"combined_vectors.npy\"))\n    faiss_index = faiss.read_index(os.path.join(load_dir, \"faiss_index.index\"))\n\n    # Load the product metadata DataFrame\n    df = pd.read_pickle(os.path.join(load_dir, \"product_metadata_df.pkl\"))\n\n    with open(os.path.join(load_dir, \"user_history.pkl\"), \"rb\") as f:\n        user_history = pickle.load(f)\n\n    with open(os.path.join(load_dir, \"trend_string.pkl\"), \"rb\") as f:\n        trend_string = pickle.load(f)\n\n    with open(os.path.join(load_dir, \"cluster_labels.pkl\"), \"rb\") as f:\n        cluster_labels = pickle.load(f)\n\n    print(f\"✅ Loaded assets from {load_dir}\")\n    return image_embeddings, text_embeddings, combined_vectors, ids, faiss_index, df, user_history, trend_string, cluster_labels\n\n# Save all assets to disk\nsave_all_assets(image_embeddings, text_embeddings, combined_embeddings, faiss_index, df, user_history, trend_string, cluster_labels)\n\n# Load all assets back from disk\nimage_embeddings, text_embeddings, combined_vectors, ids, faiss_index, df, user_history, trend_string, cluster_labels = load_all_assets()\n\n# Display basic confirmation and validation info\nprint(f\"Combined vector dimension: {combined_vectors.shape[1]}\")\nprint(f\"FAISS index dimension: {faiss_index.d}\")\nprint(f\"Trend string:\\n{trend_string[:300]}...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-22T17:22:36.215060Z","iopub.execute_input":"2025-06-22T17:22:36.215406Z","iopub.status.idle":"2025-06-22T17:22:37.026286Z","shell.execute_reply.started":"2025-06-22T17:22:36.215382Z","shell.execute_reply":"2025-06-22T17:22:37.025502Z"}},"outputs":[{"name":"stdout","text":"✅ All embeddings, metadata, user history, and trend string saved.\n✅ Loaded assets from Assets\nCombined vector dimension: 896\nFAISS index dimension: 896\nTrend string:\nA-line, A-line dress, Animal Print, Bell-sleeve, Blouse, Bodysuit, Bra, Button-down, Cardigan, Cotton, Crewneck, Crop Top, Denim, Dress, Embroidery, Fitted, Floral, Gown, Halter, Jacket, Jersey, Knit, Lace, Legging, Linen, Long Sleeve, Maxi, Maxi Dress, Midi, Mini, Mini Dress, Off Shoulder, Pant, Pl...\n","output_type":"stream"}],"execution_count":39},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}